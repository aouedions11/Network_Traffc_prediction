{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Bidirectional, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10769, 530)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = ('GEANT-OD_pair_time_convert.csv')\n",
    "dataset = pd.read_csv(dataset_path, parse_dates=[\"time\"])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD_1-1</th>\n",
       "      <th>OD_1-2</th>\n",
       "      <th>OD_1-3</th>\n",
       "      <th>OD_1-4</th>\n",
       "      <th>OD_1-5</th>\n",
       "      <th>OD_1-6</th>\n",
       "      <th>OD_1-7</th>\n",
       "      <th>OD_1-8</th>\n",
       "      <th>OD_1-9</th>\n",
       "      <th>OD_1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>OD_23-14</th>\n",
       "      <th>OD_23-15</th>\n",
       "      <th>OD_23-16</th>\n",
       "      <th>OD_23-17</th>\n",
       "      <th>OD_23-18</th>\n",
       "      <th>OD_23-19</th>\n",
       "      <th>OD_23-20</th>\n",
       "      <th>OD_23-21</th>\n",
       "      <th>OD_23-22</th>\n",
       "      <th>OD_23-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-05-04 15:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16760.79111</td>\n",
       "      <td>12407.777780</td>\n",
       "      <td>10453.848890</td>\n",
       "      <td>1468.631111</td>\n",
       "      <td>4768.444444</td>\n",
       "      <td>25290.37333</td>\n",
       "      <td>2468.515556</td>\n",
       "      <td>7984.213333</td>\n",
       "      <td>3063.937778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.395556</td>\n",
       "      <td>1212.666667</td>\n",
       "      <td>1026.391111</td>\n",
       "      <td>51508.78222</td>\n",
       "      <td>1488.951111</td>\n",
       "      <td>175293.2444</td>\n",
       "      <td>3247.164444</td>\n",
       "      <td>14.106667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 15:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16346.46222</td>\n",
       "      <td>9373.208889</td>\n",
       "      <td>8439.048889</td>\n",
       "      <td>1032.906667</td>\n",
       "      <td>1649.520000</td>\n",
       "      <td>14433.05778</td>\n",
       "      <td>3182.986667</td>\n",
       "      <td>7243.173333</td>\n",
       "      <td>3793.306667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.142222</td>\n",
       "      <td>1079.751111</td>\n",
       "      <td>529.617778</td>\n",
       "      <td>44913.43111</td>\n",
       "      <td>1410.400000</td>\n",
       "      <td>148162.8711</td>\n",
       "      <td>3669.173333</td>\n",
       "      <td>6.880000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16755.22667</td>\n",
       "      <td>10638.302220</td>\n",
       "      <td>12623.520000</td>\n",
       "      <td>721.226667</td>\n",
       "      <td>1693.057778</td>\n",
       "      <td>17066.67556</td>\n",
       "      <td>5304.195556</td>\n",
       "      <td>6696.844444</td>\n",
       "      <td>3171.315556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.048889</td>\n",
       "      <td>1750.631111</td>\n",
       "      <td>81.760000</td>\n",
       "      <td>47603.85778</td>\n",
       "      <td>1016.977778</td>\n",
       "      <td>154312.8711</td>\n",
       "      <td>3452.320000</td>\n",
       "      <td>24.488889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18488.00889</td>\n",
       "      <td>12263.697780</td>\n",
       "      <td>13389.128890</td>\n",
       "      <td>995.600000</td>\n",
       "      <td>2984.231111</td>\n",
       "      <td>13325.22667</td>\n",
       "      <td>6248.248889</td>\n",
       "      <td>5719.804444</td>\n",
       "      <td>3289.697778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.911111</td>\n",
       "      <td>3313.120000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>47023.99111</td>\n",
       "      <td>1092.017778</td>\n",
       "      <td>148199.6622</td>\n",
       "      <td>3300.613333</td>\n",
       "      <td>36.951111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13748.27556</td>\n",
       "      <td>11323.333330</td>\n",
       "      <td>14048.426670</td>\n",
       "      <td>804.044444</td>\n",
       "      <td>2698.124444</td>\n",
       "      <td>16651.25333</td>\n",
       "      <td>5761.528889</td>\n",
       "      <td>5088.204444</td>\n",
       "      <td>3262.595556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.071111</td>\n",
       "      <td>4479.644444</td>\n",
       "      <td>541.288889</td>\n",
       "      <td>47737.10222</td>\n",
       "      <td>1139.217778</td>\n",
       "      <td>147601.5467</td>\n",
       "      <td>4073.137778</td>\n",
       "      <td>59.848889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OD_1-1       OD_1-2        OD_1-3        OD_1-4  \\\n",
       "time                                                                   \n",
       "2005-05-04 15:30:00     0.0  16760.79111  12407.777780  10453.848890   \n",
       "2005-05-04 15:45:00     0.0  16346.46222   9373.208889   8439.048889   \n",
       "2005-05-04 16:00:00     0.0  16755.22667  10638.302220  12623.520000   \n",
       "2005-05-04 16:15:00     0.0  18488.00889  12263.697780  13389.128890   \n",
       "2005-05-04 16:30:00     0.0  13748.27556  11323.333330  14048.426670   \n",
       "\n",
       "                          OD_1-5       OD_1-6       OD_1-7       OD_1-8  \\\n",
       "time                                                                      \n",
       "2005-05-04 15:30:00  1468.631111  4768.444444  25290.37333  2468.515556   \n",
       "2005-05-04 15:45:00  1032.906667  1649.520000  14433.05778  3182.986667   \n",
       "2005-05-04 16:00:00   721.226667  1693.057778  17066.67556  5304.195556   \n",
       "2005-05-04 16:15:00   995.600000  2984.231111  13325.22667  6248.248889   \n",
       "2005-05-04 16:30:00   804.044444  2698.124444  16651.25333  5761.528889   \n",
       "\n",
       "                          OD_1-9      OD_1-10  ...  OD_23-14    OD_23-15  \\\n",
       "time                                           ...                         \n",
       "2005-05-04 15:30:00  7984.213333  3063.937778  ...       0.0  211.395556   \n",
       "2005-05-04 15:45:00  7243.173333  3793.306667  ...       0.0  190.142222   \n",
       "2005-05-04 16:00:00  6696.844444  3171.315556  ...       0.0   51.048889   \n",
       "2005-05-04 16:15:00  5719.804444  3289.697778  ...       0.0  217.911111   \n",
       "2005-05-04 16:30:00  5088.204444  3262.595556  ...       0.0  292.071111   \n",
       "\n",
       "                        OD_23-16     OD_23-17     OD_23-18     OD_23-19  \\\n",
       "time                                                                      \n",
       "2005-05-04 15:30:00  1212.666667  1026.391111  51508.78222  1488.951111   \n",
       "2005-05-04 15:45:00  1079.751111   529.617778  44913.43111  1410.400000   \n",
       "2005-05-04 16:00:00  1750.631111    81.760000  47603.85778  1016.977778   \n",
       "2005-05-04 16:15:00  3313.120000   356.000000  47023.99111  1092.017778   \n",
       "2005-05-04 16:30:00  4479.644444   541.288889  47737.10222  1139.217778   \n",
       "\n",
       "                        OD_23-20     OD_23-21   OD_23-22  OD_23-23  \n",
       "time                                                                \n",
       "2005-05-04 15:30:00  175293.2444  3247.164444  14.106667       0.0  \n",
       "2005-05-04 15:45:00  148162.8711  3669.173333   6.880000       0.0  \n",
       "2005-05-04 16:00:00  154312.8711  3452.320000  24.488889       0.0  \n",
       "2005-05-04 16:15:00  148199.6622  3300.613333  36.951111       0.0  \n",
       "2005-05-04 16:30:00  147601.5467  4073.137778  59.848889       0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.set_index(['time'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OD_1-1      0\n",
       "OD_1-2      0\n",
       "OD_1-3      0\n",
       "OD_1-4      0\n",
       "OD_1-5      0\n",
       "           ..\n",
       "OD_23-19    0\n",
       "OD_23-20    0\n",
       "OD_23-21    0\n",
       "OD_23-22    0\n",
       "OD_23-23    0\n",
       "Length: 529, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isnan(dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD_1-1</th>\n",
       "      <th>OD_1-2</th>\n",
       "      <th>OD_1-3</th>\n",
       "      <th>OD_1-4</th>\n",
       "      <th>OD_1-5</th>\n",
       "      <th>OD_1-6</th>\n",
       "      <th>OD_1-7</th>\n",
       "      <th>OD_1-8</th>\n",
       "      <th>OD_1-9</th>\n",
       "      <th>OD_1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>OD_23-14</th>\n",
       "      <th>OD_23-15</th>\n",
       "      <th>OD_23-16</th>\n",
       "      <th>OD_23-17</th>\n",
       "      <th>OD_23-18</th>\n",
       "      <th>OD_23-19</th>\n",
       "      <th>OD_23-20</th>\n",
       "      <th>OD_23-21</th>\n",
       "      <th>OD_23-22</th>\n",
       "      <th>OD_23-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-08-31 06:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2152.924444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847.493333</td>\n",
       "      <td>210.124444</td>\n",
       "      <td>1237.360000</td>\n",
       "      <td>68.746667</td>\n",
       "      <td>4979.697778</td>\n",
       "      <td>116.871111</td>\n",
       "      <td>1229.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9318.675556</td>\n",
       "      <td>66.871111</td>\n",
       "      <td>482.311111</td>\n",
       "      <td>2329.564444</td>\n",
       "      <td>878.035556</td>\n",
       "      <td>119879.8844</td>\n",
       "      <td>249.440000</td>\n",
       "      <td>37.022222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1030.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.946667</td>\n",
       "      <td>1531.866667</td>\n",
       "      <td>1965.822222</td>\n",
       "      <td>1.475556</td>\n",
       "      <td>5078.666667</td>\n",
       "      <td>157.457778</td>\n",
       "      <td>960.746667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.613333</td>\n",
       "      <td>77.982222</td>\n",
       "      <td>200.968889</td>\n",
       "      <td>2465.004444</td>\n",
       "      <td>960.871111</td>\n",
       "      <td>122241.0844</td>\n",
       "      <td>431.164444</td>\n",
       "      <td>24.977778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390.408889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5156.524444</td>\n",
       "      <td>4880.293333</td>\n",
       "      <td>1835.742222</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>5826.880000</td>\n",
       "      <td>149.813333</td>\n",
       "      <td>1121.991111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8911.973333</td>\n",
       "      <td>139.751111</td>\n",
       "      <td>273.537778</td>\n",
       "      <td>1968.320000</td>\n",
       "      <td>833.466667</td>\n",
       "      <td>123267.3867</td>\n",
       "      <td>403.288889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>519.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3845.191111</td>\n",
       "      <td>663.422222</td>\n",
       "      <td>1808.435556</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>2657.511111</td>\n",
       "      <td>133.413333</td>\n",
       "      <td>1038.924444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9549.253333</td>\n",
       "      <td>46.835556</td>\n",
       "      <td>254.151111</td>\n",
       "      <td>2169.271111</td>\n",
       "      <td>930.284444</td>\n",
       "      <td>119550.0000</td>\n",
       "      <td>351.555556</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.128889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243.200000</td>\n",
       "      <td>372.400000</td>\n",
       "      <td>2171.164444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2533.546667</td>\n",
       "      <td>300.497778</td>\n",
       "      <td>1237.626667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8818.835556</td>\n",
       "      <td>146.008889</td>\n",
       "      <td>370.248889</td>\n",
       "      <td>2705.857778</td>\n",
       "      <td>937.822222</td>\n",
       "      <td>117472.8622</td>\n",
       "      <td>56.648889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OD_1-1       OD_1-2  OD_1-3       OD_1-4       OD_1-5  \\\n",
       "time                                                                         \n",
       "2005-08-31 06:45:00     0.0  2152.924444     0.0  1847.493333   210.124444   \n",
       "2005-08-31 07:00:00     0.0  1030.453333     0.0  4569.946667  1531.866667   \n",
       "2005-08-31 07:15:00     0.0   390.408889     0.0  5156.524444  4880.293333   \n",
       "2005-08-31 07:30:00     0.0   519.155556     0.0  3845.191111   663.422222   \n",
       "2005-08-31 07:45:00     0.0  1131.128889     0.0  1243.200000   372.400000   \n",
       "\n",
       "                          OD_1-6     OD_1-7       OD_1-8      OD_1-9  \\\n",
       "time                                                                   \n",
       "2005-08-31 06:45:00  1237.360000  68.746667  4979.697778  116.871111   \n",
       "2005-08-31 07:00:00  1965.822222   1.475556  5078.666667  157.457778   \n",
       "2005-08-31 07:15:00  1835.742222   0.862222  5826.880000  149.813333   \n",
       "2005-08-31 07:30:00  1808.435556   0.391111  2657.511111  133.413333   \n",
       "2005-08-31 07:45:00  2171.164444   0.426667  2533.546667  300.497778   \n",
       "\n",
       "                         OD_1-10  ...  OD_23-14     OD_23-15    OD_23-16  \\\n",
       "time                              ...                                      \n",
       "2005-08-31 06:45:00  1229.848889  ...       0.0  9318.675556   66.871111   \n",
       "2005-08-31 07:00:00   960.746667  ...       0.0  9558.613333   77.982222   \n",
       "2005-08-31 07:15:00  1121.991111  ...       0.0  8911.973333  139.751111   \n",
       "2005-08-31 07:30:00  1038.924444  ...       0.0  9549.253333   46.835556   \n",
       "2005-08-31 07:45:00  1237.626667  ...       0.0  8818.835556  146.008889   \n",
       "\n",
       "                       OD_23-17     OD_23-18    OD_23-19     OD_23-20  \\\n",
       "time                                                                    \n",
       "2005-08-31 06:45:00  482.311111  2329.564444  878.035556  119879.8844   \n",
       "2005-08-31 07:00:00  200.968889  2465.004444  960.871111  122241.0844   \n",
       "2005-08-31 07:15:00  273.537778  1968.320000  833.466667  123267.3867   \n",
       "2005-08-31 07:30:00  254.151111  2169.271111  930.284444  119550.0000   \n",
       "2005-08-31 07:45:00  370.248889  2705.857778  937.822222  117472.8622   \n",
       "\n",
       "                       OD_23-21   OD_23-22  OD_23-23  \n",
       "time                                                  \n",
       "2005-08-31 06:45:00  249.440000  37.022222       0.0  \n",
       "2005-08-31 07:00:00  431.164444  24.977778       0.0  \n",
       "2005-08-31 07:15:00  403.288889   0.000000       0.0  \n",
       "2005-08-31 07:30:00  351.555556   2.622222       0.0  \n",
       "2005-08-31 07:45:00   56.648889   0.000000       0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_shape_aftersampling: (10769, 529)\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset_shape_aftersampling:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset[0:8615], dataset[8615:] # total dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (8615, 529)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD_1-1</th>\n",
       "      <th>OD_1-2</th>\n",
       "      <th>OD_1-3</th>\n",
       "      <th>OD_1-4</th>\n",
       "      <th>OD_1-5</th>\n",
       "      <th>OD_1-6</th>\n",
       "      <th>OD_1-7</th>\n",
       "      <th>OD_1-8</th>\n",
       "      <th>OD_1-9</th>\n",
       "      <th>OD_1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>OD_23-14</th>\n",
       "      <th>OD_23-15</th>\n",
       "      <th>OD_23-16</th>\n",
       "      <th>OD_23-17</th>\n",
       "      <th>OD_23-18</th>\n",
       "      <th>OD_23-19</th>\n",
       "      <th>OD_23-20</th>\n",
       "      <th>OD_23-21</th>\n",
       "      <th>OD_23-22</th>\n",
       "      <th>OD_23-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-05-04 15:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16760.79111</td>\n",
       "      <td>12407.777780</td>\n",
       "      <td>10453.848890</td>\n",
       "      <td>1468.631111</td>\n",
       "      <td>4768.444444</td>\n",
       "      <td>25290.37333</td>\n",
       "      <td>2468.515556</td>\n",
       "      <td>7984.213333</td>\n",
       "      <td>3063.937778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.395556</td>\n",
       "      <td>1212.666667</td>\n",
       "      <td>1026.391111</td>\n",
       "      <td>51508.78222</td>\n",
       "      <td>1488.951111</td>\n",
       "      <td>175293.2444</td>\n",
       "      <td>3247.164444</td>\n",
       "      <td>14.106667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 15:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16346.46222</td>\n",
       "      <td>9373.208889</td>\n",
       "      <td>8439.048889</td>\n",
       "      <td>1032.906667</td>\n",
       "      <td>1649.520000</td>\n",
       "      <td>14433.05778</td>\n",
       "      <td>3182.986667</td>\n",
       "      <td>7243.173333</td>\n",
       "      <td>3793.306667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.142222</td>\n",
       "      <td>1079.751111</td>\n",
       "      <td>529.617778</td>\n",
       "      <td>44913.43111</td>\n",
       "      <td>1410.400000</td>\n",
       "      <td>148162.8711</td>\n",
       "      <td>3669.173333</td>\n",
       "      <td>6.880000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16755.22667</td>\n",
       "      <td>10638.302220</td>\n",
       "      <td>12623.520000</td>\n",
       "      <td>721.226667</td>\n",
       "      <td>1693.057778</td>\n",
       "      <td>17066.67556</td>\n",
       "      <td>5304.195556</td>\n",
       "      <td>6696.844444</td>\n",
       "      <td>3171.315556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.048889</td>\n",
       "      <td>1750.631111</td>\n",
       "      <td>81.760000</td>\n",
       "      <td>47603.85778</td>\n",
       "      <td>1016.977778</td>\n",
       "      <td>154312.8711</td>\n",
       "      <td>3452.320000</td>\n",
       "      <td>24.488889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18488.00889</td>\n",
       "      <td>12263.697780</td>\n",
       "      <td>13389.128890</td>\n",
       "      <td>995.600000</td>\n",
       "      <td>2984.231111</td>\n",
       "      <td>13325.22667</td>\n",
       "      <td>6248.248889</td>\n",
       "      <td>5719.804444</td>\n",
       "      <td>3289.697778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.911111</td>\n",
       "      <td>3313.120000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>47023.99111</td>\n",
       "      <td>1092.017778</td>\n",
       "      <td>148199.6622</td>\n",
       "      <td>3300.613333</td>\n",
       "      <td>36.951111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-04 16:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13748.27556</td>\n",
       "      <td>11323.333330</td>\n",
       "      <td>14048.426670</td>\n",
       "      <td>804.044444</td>\n",
       "      <td>2698.124444</td>\n",
       "      <td>16651.25333</td>\n",
       "      <td>5761.528889</td>\n",
       "      <td>5088.204444</td>\n",
       "      <td>3262.595556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.071111</td>\n",
       "      <td>4479.644444</td>\n",
       "      <td>541.288889</td>\n",
       "      <td>47737.10222</td>\n",
       "      <td>1139.217778</td>\n",
       "      <td>147601.5467</td>\n",
       "      <td>4073.137778</td>\n",
       "      <td>59.848889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OD_1-1       OD_1-2        OD_1-3        OD_1-4  \\\n",
       "time                                                                   \n",
       "2005-05-04 15:30:00     0.0  16760.79111  12407.777780  10453.848890   \n",
       "2005-05-04 15:45:00     0.0  16346.46222   9373.208889   8439.048889   \n",
       "2005-05-04 16:00:00     0.0  16755.22667  10638.302220  12623.520000   \n",
       "2005-05-04 16:15:00     0.0  18488.00889  12263.697780  13389.128890   \n",
       "2005-05-04 16:30:00     0.0  13748.27556  11323.333330  14048.426670   \n",
       "\n",
       "                          OD_1-5       OD_1-6       OD_1-7       OD_1-8  \\\n",
       "time                                                                      \n",
       "2005-05-04 15:30:00  1468.631111  4768.444444  25290.37333  2468.515556   \n",
       "2005-05-04 15:45:00  1032.906667  1649.520000  14433.05778  3182.986667   \n",
       "2005-05-04 16:00:00   721.226667  1693.057778  17066.67556  5304.195556   \n",
       "2005-05-04 16:15:00   995.600000  2984.231111  13325.22667  6248.248889   \n",
       "2005-05-04 16:30:00   804.044444  2698.124444  16651.25333  5761.528889   \n",
       "\n",
       "                          OD_1-9      OD_1-10  ...  OD_23-14    OD_23-15  \\\n",
       "time                                           ...                         \n",
       "2005-05-04 15:30:00  7984.213333  3063.937778  ...       0.0  211.395556   \n",
       "2005-05-04 15:45:00  7243.173333  3793.306667  ...       0.0  190.142222   \n",
       "2005-05-04 16:00:00  6696.844444  3171.315556  ...       0.0   51.048889   \n",
       "2005-05-04 16:15:00  5719.804444  3289.697778  ...       0.0  217.911111   \n",
       "2005-05-04 16:30:00  5088.204444  3262.595556  ...       0.0  292.071111   \n",
       "\n",
       "                        OD_23-16     OD_23-17     OD_23-18     OD_23-19  \\\n",
       "time                                                                      \n",
       "2005-05-04 15:30:00  1212.666667  1026.391111  51508.78222  1488.951111   \n",
       "2005-05-04 15:45:00  1079.751111   529.617778  44913.43111  1410.400000   \n",
       "2005-05-04 16:00:00  1750.631111    81.760000  47603.85778  1016.977778   \n",
       "2005-05-04 16:15:00  3313.120000   356.000000  47023.99111  1092.017778   \n",
       "2005-05-04 16:30:00  4479.644444   541.288889  47737.10222  1139.217778   \n",
       "\n",
       "                        OD_23-20     OD_23-21   OD_23-22  OD_23-23  \n",
       "time                                                                \n",
       "2005-05-04 15:30:00  175293.2444  3247.164444  14.106667       0.0  \n",
       "2005-05-04 15:45:00  148162.8711  3669.173333   6.880000       0.0  \n",
       "2005-05-04 16:00:00  154312.8711  3452.320000  24.488889       0.0  \n",
       "2005-05-04 16:15:00  148199.6622  3300.613333  36.951111       0.0  \n",
       "2005-05-04 16:30:00  147601.5467  4073.137778  59.848889       0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train_shape:\", train_df.shape) \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_shape: (2154, 529)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OD_1-1</th>\n",
       "      <th>OD_1-2</th>\n",
       "      <th>OD_1-3</th>\n",
       "      <th>OD_1-4</th>\n",
       "      <th>OD_1-5</th>\n",
       "      <th>OD_1-6</th>\n",
       "      <th>OD_1-7</th>\n",
       "      <th>OD_1-8</th>\n",
       "      <th>OD_1-9</th>\n",
       "      <th>OD_1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>OD_23-14</th>\n",
       "      <th>OD_23-15</th>\n",
       "      <th>OD_23-16</th>\n",
       "      <th>OD_23-17</th>\n",
       "      <th>OD_23-18</th>\n",
       "      <th>OD_23-19</th>\n",
       "      <th>OD_23-20</th>\n",
       "      <th>OD_23-21</th>\n",
       "      <th>OD_23-22</th>\n",
       "      <th>OD_23-23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-08-31 06:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2152.924444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847.493333</td>\n",
       "      <td>210.124444</td>\n",
       "      <td>1237.360000</td>\n",
       "      <td>68.746667</td>\n",
       "      <td>4979.697778</td>\n",
       "      <td>116.871111</td>\n",
       "      <td>1229.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9318.675556</td>\n",
       "      <td>66.871111</td>\n",
       "      <td>482.311111</td>\n",
       "      <td>2329.564444</td>\n",
       "      <td>878.035556</td>\n",
       "      <td>119879.8844</td>\n",
       "      <td>249.440000</td>\n",
       "      <td>37.022222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1030.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.946667</td>\n",
       "      <td>1531.866667</td>\n",
       "      <td>1965.822222</td>\n",
       "      <td>1.475556</td>\n",
       "      <td>5078.666667</td>\n",
       "      <td>157.457778</td>\n",
       "      <td>960.746667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.613333</td>\n",
       "      <td>77.982222</td>\n",
       "      <td>200.968889</td>\n",
       "      <td>2465.004444</td>\n",
       "      <td>960.871111</td>\n",
       "      <td>122241.0844</td>\n",
       "      <td>431.164444</td>\n",
       "      <td>24.977778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390.408889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5156.524444</td>\n",
       "      <td>4880.293333</td>\n",
       "      <td>1835.742222</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>5826.880000</td>\n",
       "      <td>149.813333</td>\n",
       "      <td>1121.991111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8911.973333</td>\n",
       "      <td>139.751111</td>\n",
       "      <td>273.537778</td>\n",
       "      <td>1968.320000</td>\n",
       "      <td>833.466667</td>\n",
       "      <td>123267.3867</td>\n",
       "      <td>403.288889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>519.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3845.191111</td>\n",
       "      <td>663.422222</td>\n",
       "      <td>1808.435556</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>2657.511111</td>\n",
       "      <td>133.413333</td>\n",
       "      <td>1038.924444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9549.253333</td>\n",
       "      <td>46.835556</td>\n",
       "      <td>254.151111</td>\n",
       "      <td>2169.271111</td>\n",
       "      <td>930.284444</td>\n",
       "      <td>119550.0000</td>\n",
       "      <td>351.555556</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-08-31 07:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.128889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243.200000</td>\n",
       "      <td>372.400000</td>\n",
       "      <td>2171.164444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2533.546667</td>\n",
       "      <td>300.497778</td>\n",
       "      <td>1237.626667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8818.835556</td>\n",
       "      <td>146.008889</td>\n",
       "      <td>370.248889</td>\n",
       "      <td>2705.857778</td>\n",
       "      <td>937.822222</td>\n",
       "      <td>117472.8622</td>\n",
       "      <td>56.648889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OD_1-1       OD_1-2  OD_1-3       OD_1-4       OD_1-5  \\\n",
       "time                                                                         \n",
       "2005-08-31 06:45:00     0.0  2152.924444     0.0  1847.493333   210.124444   \n",
       "2005-08-31 07:00:00     0.0  1030.453333     0.0  4569.946667  1531.866667   \n",
       "2005-08-31 07:15:00     0.0   390.408889     0.0  5156.524444  4880.293333   \n",
       "2005-08-31 07:30:00     0.0   519.155556     0.0  3845.191111   663.422222   \n",
       "2005-08-31 07:45:00     0.0  1131.128889     0.0  1243.200000   372.400000   \n",
       "\n",
       "                          OD_1-6     OD_1-7       OD_1-8      OD_1-9  \\\n",
       "time                                                                   \n",
       "2005-08-31 06:45:00  1237.360000  68.746667  4979.697778  116.871111   \n",
       "2005-08-31 07:00:00  1965.822222   1.475556  5078.666667  157.457778   \n",
       "2005-08-31 07:15:00  1835.742222   0.862222  5826.880000  149.813333   \n",
       "2005-08-31 07:30:00  1808.435556   0.391111  2657.511111  133.413333   \n",
       "2005-08-31 07:45:00  2171.164444   0.426667  2533.546667  300.497778   \n",
       "\n",
       "                         OD_1-10  ...  OD_23-14     OD_23-15    OD_23-16  \\\n",
       "time                              ...                                      \n",
       "2005-08-31 06:45:00  1229.848889  ...       0.0  9318.675556   66.871111   \n",
       "2005-08-31 07:00:00   960.746667  ...       0.0  9558.613333   77.982222   \n",
       "2005-08-31 07:15:00  1121.991111  ...       0.0  8911.973333  139.751111   \n",
       "2005-08-31 07:30:00  1038.924444  ...       0.0  9549.253333   46.835556   \n",
       "2005-08-31 07:45:00  1237.626667  ...       0.0  8818.835556  146.008889   \n",
       "\n",
       "                       OD_23-17     OD_23-18    OD_23-19     OD_23-20  \\\n",
       "time                                                                    \n",
       "2005-08-31 06:45:00  482.311111  2329.564444  878.035556  119879.8844   \n",
       "2005-08-31 07:00:00  200.968889  2465.004444  960.871111  122241.0844   \n",
       "2005-08-31 07:15:00  273.537778  1968.320000  833.466667  123267.3867   \n",
       "2005-08-31 07:30:00  254.151111  2169.271111  930.284444  119550.0000   \n",
       "2005-08-31 07:45:00  370.248889  2705.857778  937.822222  117472.8622   \n",
       "\n",
       "                       OD_23-21   OD_23-22  OD_23-23  \n",
       "time                                                  \n",
       "2005-08-31 06:45:00  249.440000  37.022222       0.0  \n",
       "2005-08-31 07:00:00  431.164444  24.977778       0.0  \n",
       "2005-08-31 07:15:00  403.288889   0.000000       0.0  \n",
       "2005-08-31 07:30:00  351.555556   2.622222       0.0  \n",
       "2005-08-31 07:45:00   56.648889   0.000000       0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test_shape:\",test_df.shape)\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "sc=sc.fit(train_df)\n",
    "train_df = sc.transform(train_df)\n",
    "test_df = sc.transform(test_df)\n",
    "#print(\"train_df\", train_df)\n",
    "#print(\"test_df\", test_df)\n",
    "train_df=pd.DataFrame(train_df) \n",
    "test_df=pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.075669</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>9.941869e-07</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.059015</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.303416e-06</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.026052</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>2.194196e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.057213</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.085489</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.062410</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.085602</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.168344e-06</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6    \\\n",
       "8610  0.0  0.000857  0.002327  0.035872  0.075669  0.000034  0.000000   \n",
       "8611  0.0  0.000581  0.001609  0.021112  0.047583  0.000038  0.000016   \n",
       "8612  0.0  0.000475  0.002059  0.026052  0.043870  0.000070  0.000008   \n",
       "8613  0.0  0.000349  0.000688  0.085489  0.016884  0.000033  0.000170   \n",
       "8614  0.0  0.000402  0.002810  0.085602  0.023443  0.000055  0.000021   \n",
       "\n",
       "           7             8         9    ...  519       520       521  \\\n",
       "8610  0.000059  9.941869e-07  0.000206  ...  0.0  0.002203  0.046844   \n",
       "8611  0.000034  5.303416e-06  0.000310  ...  0.0  0.001611  0.033565   \n",
       "8612  0.000043  2.194196e-06  0.000304  ...  0.0  0.002944  0.031120   \n",
       "8613  0.000017  0.000000e+00  0.000288  ...  0.0  0.001621  0.022668   \n",
       "8614  0.000035  1.168344e-06  0.000340  ...  0.0  0.001343  0.027190   \n",
       "\n",
       "           522       523       524       525       526       527  528  \n",
       "8610  0.027464  0.015558  0.059015  0.007426  0.000007  0.000125  0.0  \n",
       "8611  0.029432  0.016792  0.044569  0.007726  0.000005  0.002145  0.0  \n",
       "8612  0.025830  0.017493  0.057213  0.007939  0.000003  0.000081  0.0  \n",
       "8613  0.022845  0.019531  0.062410  0.007812  0.000012  0.000202  0.0  \n",
       "8614  0.024130  0.015608  0.063531  0.007959  0.000010  0.000160  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107327</td>\n",
       "      <td>0.120661</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068285</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121103</td>\n",
       "      <td>0.384409</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090306</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068218</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1    2         3         4         5         6         7    \\\n",
       "2149  0.0  0.026102  0.0  0.043389  0.016551  0.000065  0.000405  0.000261   \n",
       "2150  0.0  0.012493  0.0  0.107327  0.120661  0.000103  0.000009  0.000266   \n",
       "2151  0.0  0.004733  0.0  0.121103  0.384409  0.000096  0.000005  0.000305   \n",
       "2152  0.0  0.006294  0.0  0.090306  0.052256  0.000095  0.000002  0.000139   \n",
       "2153  0.0  0.013714  0.0  0.029197  0.029333  0.000114  0.000003  0.000133   \n",
       "\n",
       "           8         9    ...  519       520       521       522       523  \\\n",
       "2149  0.000006  0.000064  ...  0.0  0.066571  0.002322  0.023177  0.001981   \n",
       "2150  0.000008  0.000050  ...  0.0  0.068285  0.002711  0.009657  0.002193   \n",
       "2151  0.000008  0.000059  ...  0.0  0.063666  0.004873  0.013145  0.001417   \n",
       "2152  0.000007  0.000054  ...  0.0  0.068218  0.001620  0.012213  0.001731   \n",
       "2153  0.000016  0.000065  ...  0.0  0.063000  0.005092  0.017792  0.002570   \n",
       "\n",
       "           524       525       526       527  528  \n",
       "2149  0.045390  0.005981  0.000013  0.003035  0.0  \n",
       "2150  0.049673  0.006105  0.000023  0.002048  0.0  \n",
       "2151  0.043085  0.006159  0.000021  0.000000  0.0  \n",
       "2152  0.048092  0.005964  0.000018  0.000215  0.0  \n",
       "2153  0.048482  0.005855  0.000003  0.000000  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.720000</td>\n",
       "      <td>77.964444</td>\n",
       "      <td>1527.404444</td>\n",
       "      <td>960.666667</td>\n",
       "      <td>648.417778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1131.537778</td>\n",
       "      <td>18.977778</td>\n",
       "      <td>3935.955556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.400000</td>\n",
       "      <td>1338.568889</td>\n",
       "      <td>571.528889</td>\n",
       "      <td>11014.88000</td>\n",
       "      <td>1141.511111</td>\n",
       "      <td>147450.4356</td>\n",
       "      <td>136.568889</td>\n",
       "      <td>1.528889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>47.884444</td>\n",
       "      <td>53.902222</td>\n",
       "      <td>898.933333</td>\n",
       "      <td>604.088889</td>\n",
       "      <td>726.968889</td>\n",
       "      <td>2.702222</td>\n",
       "      <td>652.826667</td>\n",
       "      <td>101.235556</td>\n",
       "      <td>5920.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.528889</td>\n",
       "      <td>959.280000</td>\n",
       "      <td>612.488889</td>\n",
       "      <td>11804.60444</td>\n",
       "      <td>862.160000</td>\n",
       "      <td>153175.2089</td>\n",
       "      <td>101.377778</td>\n",
       "      <td>26.168889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.173333</td>\n",
       "      <td>68.995556</td>\n",
       "      <td>1109.288889</td>\n",
       "      <td>556.951111</td>\n",
       "      <td>1327.840000</td>\n",
       "      <td>1.422222</td>\n",
       "      <td>823.288889</td>\n",
       "      <td>41.884444</td>\n",
       "      <td>5803.137778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.062222</td>\n",
       "      <td>889.431111</td>\n",
       "      <td>537.528889</td>\n",
       "      <td>12252.74667</td>\n",
       "      <td>1106.666667</td>\n",
       "      <td>157235.1378</td>\n",
       "      <td>65.031111</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.791111</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>3640.097778</td>\n",
       "      <td>214.355556</td>\n",
       "      <td>627.591111</td>\n",
       "      <td>28.826667</td>\n",
       "      <td>330.151111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5495.191111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.951111</td>\n",
       "      <td>648.008889</td>\n",
       "      <td>475.395556</td>\n",
       "      <td>13557.05778</td>\n",
       "      <td>1207.155556</td>\n",
       "      <td>154806.0000</td>\n",
       "      <td>231.946667</td>\n",
       "      <td>2.462222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.137778</td>\n",
       "      <td>94.160000</td>\n",
       "      <td>3644.897778</td>\n",
       "      <td>297.617778</td>\n",
       "      <td>1047.680000</td>\n",
       "      <td>3.626667</td>\n",
       "      <td>664.560000</td>\n",
       "      <td>22.302222</td>\n",
       "      <td>6484.942222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.991111</td>\n",
       "      <td>777.182222</td>\n",
       "      <td>502.142222</td>\n",
       "      <td>11047.41333</td>\n",
       "      <td>1228.835556</td>\n",
       "      <td>157610.7911</td>\n",
       "      <td>200.168889</td>\n",
       "      <td>1.955556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2            3           4            5    \\\n",
       "8610  0.0  70.720000  77.964444  1527.404444  960.666667   648.417778   \n",
       "8611  0.0  47.884444  53.902222   898.933333  604.088889   726.968889   \n",
       "8612  0.0  39.173333  68.995556  1109.288889  556.951111  1327.840000   \n",
       "8613  0.0  28.791111  23.040000  3640.097778  214.355556   627.591111   \n",
       "8614  0.0  33.137778  94.160000  3644.897778  297.617778  1047.680000   \n",
       "\n",
       "            6            7           8            9    ...  519         520  \\\n",
       "8610   0.000000  1131.537778   18.977778  3935.955556  ...  0.0  308.400000   \n",
       "8611   2.702222   652.826667  101.235556  5920.888889  ...  0.0  225.528889   \n",
       "8612   1.422222   823.288889   41.884444  5803.137778  ...  0.0  412.062222   \n",
       "8613  28.826667   330.151111    0.000000  5495.191111  ...  0.0  226.951111   \n",
       "8614   3.626667   664.560000   22.302222  6484.942222  ...  0.0  187.991111   \n",
       "\n",
       "              521         522          523          524          525  \\\n",
       "8610  1338.568889  571.528889  11014.88000  1141.511111  147450.4356   \n",
       "8611   959.280000  612.488889  11804.60444   862.160000  153175.2089   \n",
       "8612   889.431111  537.528889  12252.74667  1106.666667  157235.1378   \n",
       "8613   648.008889  475.395556  13557.05778  1207.155556  154806.0000   \n",
       "8614   777.182222  502.142222  11047.41333  1228.835556  157610.7911   \n",
       "\n",
       "             526        527  528  \n",
       "8610  136.568889   1.528889  0.0  \n",
       "8611  101.377778  26.168889  0.0  \n",
       "8612   65.031111   0.986667  0.0  \n",
       "8613  231.946667   2.462222  0.0  \n",
       "8614  200.168889   1.955556  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_inverse=sc.inverse_transform(train_df)\n",
    "train_df_inverse=pd.DataFrame(train_df_inverse)\n",
    "train_df_inverse.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2152.924444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847.493333</td>\n",
       "      <td>210.124444</td>\n",
       "      <td>1237.360000</td>\n",
       "      <td>68.746667</td>\n",
       "      <td>4979.697778</td>\n",
       "      <td>116.871111</td>\n",
       "      <td>1229.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9318.675556</td>\n",
       "      <td>66.871111</td>\n",
       "      <td>482.311111</td>\n",
       "      <td>2329.564444</td>\n",
       "      <td>878.035556</td>\n",
       "      <td>119879.8844</td>\n",
       "      <td>249.440000</td>\n",
       "      <td>37.022222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1030.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.946667</td>\n",
       "      <td>1531.866667</td>\n",
       "      <td>1965.822222</td>\n",
       "      <td>1.475556</td>\n",
       "      <td>5078.666667</td>\n",
       "      <td>157.457778</td>\n",
       "      <td>960.746667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.613333</td>\n",
       "      <td>77.982222</td>\n",
       "      <td>200.968889</td>\n",
       "      <td>2465.004444</td>\n",
       "      <td>960.871111</td>\n",
       "      <td>122241.0844</td>\n",
       "      <td>431.164444</td>\n",
       "      <td>24.977778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390.408889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5156.524444</td>\n",
       "      <td>4880.293333</td>\n",
       "      <td>1835.742222</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>5826.880000</td>\n",
       "      <td>149.813333</td>\n",
       "      <td>1121.991111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8911.973333</td>\n",
       "      <td>139.751111</td>\n",
       "      <td>273.537778</td>\n",
       "      <td>1968.320000</td>\n",
       "      <td>833.466667</td>\n",
       "      <td>123267.3867</td>\n",
       "      <td>403.288889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>519.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3845.191111</td>\n",
       "      <td>663.422222</td>\n",
       "      <td>1808.435556</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>2657.511111</td>\n",
       "      <td>133.413333</td>\n",
       "      <td>1038.924444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9549.253333</td>\n",
       "      <td>46.835556</td>\n",
       "      <td>254.151111</td>\n",
       "      <td>2169.271111</td>\n",
       "      <td>930.284444</td>\n",
       "      <td>119550.0000</td>\n",
       "      <td>351.555556</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.128889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243.200000</td>\n",
       "      <td>372.400000</td>\n",
       "      <td>2171.164444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2533.546667</td>\n",
       "      <td>300.497778</td>\n",
       "      <td>1237.626667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8818.835556</td>\n",
       "      <td>146.008889</td>\n",
       "      <td>370.248889</td>\n",
       "      <td>2705.857778</td>\n",
       "      <td>937.822222</td>\n",
       "      <td>117472.8622</td>\n",
       "      <td>56.648889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1    2            3            4            5          6    \\\n",
       "2149  0.0  2152.924444  0.0  1847.493333   210.124444  1237.360000  68.746667   \n",
       "2150  0.0  1030.453333  0.0  4569.946667  1531.866667  1965.822222   1.475556   \n",
       "2151  0.0   390.408889  0.0  5156.524444  4880.293333  1835.742222   0.862222   \n",
       "2152  0.0   519.155556  0.0  3845.191111   663.422222  1808.435556   0.391111   \n",
       "2153  0.0  1131.128889  0.0  1243.200000   372.400000  2171.164444   0.426667   \n",
       "\n",
       "              7           8            9    ...  519          520         521  \\\n",
       "2149  4979.697778  116.871111  1229.848889  ...  0.0  9318.675556   66.871111   \n",
       "2150  5078.666667  157.457778   960.746667  ...  0.0  9558.613333   77.982222   \n",
       "2151  5826.880000  149.813333  1121.991111  ...  0.0  8911.973333  139.751111   \n",
       "2152  2657.511111  133.413333  1038.924444  ...  0.0  9549.253333   46.835556   \n",
       "2153  2533.546667  300.497778  1237.626667  ...  0.0  8818.835556  146.008889   \n",
       "\n",
       "             522          523         524          525         526        527  \\\n",
       "2149  482.311111  2329.564444  878.035556  119879.8844  249.440000  37.022222   \n",
       "2150  200.968889  2465.004444  960.871111  122241.0844  431.164444  24.977778   \n",
       "2151  273.537778  1968.320000  833.466667  123267.3867  403.288889   0.000000   \n",
       "2152  254.151111  2169.271111  930.284444  119550.0000  351.555556   2.622222   \n",
       "2153  370.248889  2705.857778  937.822222  117472.8622   56.648889   0.000000   \n",
       "\n",
       "      528  \n",
       "2149  0.0  \n",
       "2150  0.0  \n",
       "2151  0.0  \n",
       "2152  0.0  \n",
       "2153  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_inverse=sc.inverse_transform(test_df)\n",
    "test_df_inverse=pd.DataFrame(test_df_inverse)\n",
    "test_df_inverse.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the time series to samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y , time_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in tqdm (range(len(X)-time_step)):\n",
    "        v=X.iloc[i:(i+time_step)].to_numpy()\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i+time_step])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8603/8603 [00:00<00:00, 10053.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2142/2142 [00:00<00:00, 8135.28it/s]\n"
     ]
    }
   ],
   "source": [
    "TIME_STEP=12\n",
    "x_train, y_train = create_dataset(train_df, train_df, TIME_STEP)\n",
    "x_test, y_test = create_dataset(test_df, test_df, TIME_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape: (8603, 12, 529)\n",
      "y_train_shape: (8603, 529)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.075669</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>9.941869e-07</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.059015</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.303416e-06</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>0.007726</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.026052</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>2.194196e-06</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.031120</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.057213</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.085489</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.062410</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.085602</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.168344e-06</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6    \\\n",
       "8598  0.0  0.000857  0.002327  0.035872  0.075669  0.000034  0.000000   \n",
       "8599  0.0  0.000581  0.001609  0.021112  0.047583  0.000038  0.000016   \n",
       "8600  0.0  0.000475  0.002059  0.026052  0.043870  0.000070  0.000008   \n",
       "8601  0.0  0.000349  0.000688  0.085489  0.016884  0.000033  0.000170   \n",
       "8602  0.0  0.000402  0.002810  0.085602  0.023443  0.000055  0.000021   \n",
       "\n",
       "           7             8         9    ...  519       520       521  \\\n",
       "8598  0.000059  9.941869e-07  0.000206  ...  0.0  0.002203  0.046844   \n",
       "8599  0.000034  5.303416e-06  0.000310  ...  0.0  0.001611  0.033565   \n",
       "8600  0.000043  2.194196e-06  0.000304  ...  0.0  0.002944  0.031120   \n",
       "8601  0.000017  0.000000e+00  0.000288  ...  0.0  0.001621  0.022668   \n",
       "8602  0.000035  1.168344e-06  0.000340  ...  0.0  0.001343  0.027190   \n",
       "\n",
       "           522       523       524       525       526       527  528  \n",
       "8598  0.027464  0.015558  0.059015  0.007426  0.000007  0.000125  0.0  \n",
       "8599  0.029432  0.016792  0.044569  0.007726  0.000005  0.002145  0.0  \n",
       "8600  0.025830  0.017493  0.057213  0.007939  0.000003  0.000081  0.0  \n",
       "8601  0.022845  0.019531  0.062410  0.007812  0.000012  0.000202  0.0  \n",
       "8602  0.024130  0.015608  0.063531  0.007959  0.000010  0.000160  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"x_train_shape:\", x_train.shape)\n",
    "#print(\"x_train:\", x_train)\n",
    "print(\"y_train_shape:\", y_train.shape)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70.720000</td>\n",
       "      <td>77.964444</td>\n",
       "      <td>1527.404444</td>\n",
       "      <td>960.666667</td>\n",
       "      <td>648.417778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1131.537778</td>\n",
       "      <td>18.977778</td>\n",
       "      <td>3935.955556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.400000</td>\n",
       "      <td>1338.568889</td>\n",
       "      <td>571.528889</td>\n",
       "      <td>11014.88000</td>\n",
       "      <td>1141.511111</td>\n",
       "      <td>147450.4356</td>\n",
       "      <td>136.568889</td>\n",
       "      <td>1.528889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>47.884444</td>\n",
       "      <td>53.902222</td>\n",
       "      <td>898.933333</td>\n",
       "      <td>604.088889</td>\n",
       "      <td>726.968889</td>\n",
       "      <td>2.702222</td>\n",
       "      <td>652.826667</td>\n",
       "      <td>101.235556</td>\n",
       "      <td>5920.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.528889</td>\n",
       "      <td>959.280000</td>\n",
       "      <td>612.488889</td>\n",
       "      <td>11804.60444</td>\n",
       "      <td>862.160000</td>\n",
       "      <td>153175.2089</td>\n",
       "      <td>101.377778</td>\n",
       "      <td>26.168889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39.173333</td>\n",
       "      <td>68.995556</td>\n",
       "      <td>1109.288889</td>\n",
       "      <td>556.951111</td>\n",
       "      <td>1327.840000</td>\n",
       "      <td>1.422222</td>\n",
       "      <td>823.288889</td>\n",
       "      <td>41.884444</td>\n",
       "      <td>5803.137778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.062222</td>\n",
       "      <td>889.431111</td>\n",
       "      <td>537.528889</td>\n",
       "      <td>12252.74667</td>\n",
       "      <td>1106.666667</td>\n",
       "      <td>157235.1378</td>\n",
       "      <td>65.031111</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.791111</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>3640.097778</td>\n",
       "      <td>214.355556</td>\n",
       "      <td>627.591111</td>\n",
       "      <td>28.826667</td>\n",
       "      <td>330.151111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5495.191111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226.951111</td>\n",
       "      <td>648.008889</td>\n",
       "      <td>475.395556</td>\n",
       "      <td>13557.05778</td>\n",
       "      <td>1207.155556</td>\n",
       "      <td>154806.0000</td>\n",
       "      <td>231.946667</td>\n",
       "      <td>2.462222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.137778</td>\n",
       "      <td>94.160000</td>\n",
       "      <td>3644.897778</td>\n",
       "      <td>297.617778</td>\n",
       "      <td>1047.680000</td>\n",
       "      <td>3.626667</td>\n",
       "      <td>664.560000</td>\n",
       "      <td>22.302222</td>\n",
       "      <td>6484.942222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.991111</td>\n",
       "      <td>777.182222</td>\n",
       "      <td>502.142222</td>\n",
       "      <td>11047.41333</td>\n",
       "      <td>1228.835556</td>\n",
       "      <td>157610.7911</td>\n",
       "      <td>200.168889</td>\n",
       "      <td>1.955556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2            3           4            5    \\\n",
       "8598  0.0  70.720000  77.964444  1527.404444  960.666667   648.417778   \n",
       "8599  0.0  47.884444  53.902222   898.933333  604.088889   726.968889   \n",
       "8600  0.0  39.173333  68.995556  1109.288889  556.951111  1327.840000   \n",
       "8601  0.0  28.791111  23.040000  3640.097778  214.355556   627.591111   \n",
       "8602  0.0  33.137778  94.160000  3644.897778  297.617778  1047.680000   \n",
       "\n",
       "            6            7           8            9    ...  519         520  \\\n",
       "8598   0.000000  1131.537778   18.977778  3935.955556  ...  0.0  308.400000   \n",
       "8599   2.702222   652.826667  101.235556  5920.888889  ...  0.0  225.528889   \n",
       "8600   1.422222   823.288889   41.884444  5803.137778  ...  0.0  412.062222   \n",
       "8601  28.826667   330.151111    0.000000  5495.191111  ...  0.0  226.951111   \n",
       "8602   3.626667   664.560000   22.302222  6484.942222  ...  0.0  187.991111   \n",
       "\n",
       "              521         522          523          524          525  \\\n",
       "8598  1338.568889  571.528889  11014.88000  1141.511111  147450.4356   \n",
       "8599   959.280000  612.488889  11804.60444   862.160000  153175.2089   \n",
       "8600   889.431111  537.528889  12252.74667  1106.666667  157235.1378   \n",
       "8601   648.008889  475.395556  13557.05778  1207.155556  154806.0000   \n",
       "8602   777.182222  502.142222  11047.41333  1228.835556  157610.7911   \n",
       "\n",
       "             526        527  528  \n",
       "8598  136.568889   1.528889  0.0  \n",
       "8599  101.377778  26.168889  0.0  \n",
       "8600   65.031111   0.986667  0.0  \n",
       "8601  231.946667   2.462222  0.0  \n",
       "8602  200.168889   1.955556  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_inverse_verif=sc.inverse_transform(y_train)\n",
    "y_train_inverse_verif=pd.DataFrame(y_train_inverse_verif)\n",
    "y_train_inverse_verif.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_shape: (2142, 12, 529)\n",
      "y_test_shape: (2142, 529)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107327</td>\n",
       "      <td>0.120661</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068285</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121103</td>\n",
       "      <td>0.384409</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090306</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068218</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1    2         3         4         5         6         7    \\\n",
       "2137  0.0  0.026102  0.0  0.043389  0.016551  0.000065  0.000405  0.000261   \n",
       "2138  0.0  0.012493  0.0  0.107327  0.120661  0.000103  0.000009  0.000266   \n",
       "2139  0.0  0.004733  0.0  0.121103  0.384409  0.000096  0.000005  0.000305   \n",
       "2140  0.0  0.006294  0.0  0.090306  0.052256  0.000095  0.000002  0.000139   \n",
       "2141  0.0  0.013714  0.0  0.029197  0.029333  0.000114  0.000003  0.000133   \n",
       "\n",
       "           8         9    ...  519       520       521       522       523  \\\n",
       "2137  0.000006  0.000064  ...  0.0  0.066571  0.002322  0.023177  0.001981   \n",
       "2138  0.000008  0.000050  ...  0.0  0.068285  0.002711  0.009657  0.002193   \n",
       "2139  0.000008  0.000059  ...  0.0  0.063666  0.004873  0.013145  0.001417   \n",
       "2140  0.000007  0.000054  ...  0.0  0.068218  0.001620  0.012213  0.001731   \n",
       "2141  0.000016  0.000065  ...  0.0  0.063000  0.005092  0.017792  0.002570   \n",
       "\n",
       "           524       525       526       527  528  \n",
       "2137  0.045390  0.005981  0.000013  0.003035  0.0  \n",
       "2138  0.049673  0.006105  0.000023  0.002048  0.0  \n",
       "2139  0.043085  0.006159  0.000021  0.000000  0.0  \n",
       "2140  0.048092  0.005964  0.000018  0.000215  0.0  \n",
       "2141  0.048482  0.005855  0.000003  0.000000  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"x_test_shape:\", x_test.shape)\n",
    "#print(\"x_test\", x_test)\n",
    "print(\"y_test_shape:\", y_test.shape)\n",
    "y_test=pd.DataFrame(y_test)\n",
    "y_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2152.924444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847.493333</td>\n",
       "      <td>210.124444</td>\n",
       "      <td>1237.360000</td>\n",
       "      <td>68.746667</td>\n",
       "      <td>4979.697778</td>\n",
       "      <td>116.871111</td>\n",
       "      <td>1229.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9318.675556</td>\n",
       "      <td>66.871111</td>\n",
       "      <td>482.311111</td>\n",
       "      <td>2329.564444</td>\n",
       "      <td>878.035556</td>\n",
       "      <td>119879.8844</td>\n",
       "      <td>249.440000</td>\n",
       "      <td>37.022222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1030.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4569.946667</td>\n",
       "      <td>1531.866667</td>\n",
       "      <td>1965.822222</td>\n",
       "      <td>1.475556</td>\n",
       "      <td>5078.666667</td>\n",
       "      <td>157.457778</td>\n",
       "      <td>960.746667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.613333</td>\n",
       "      <td>77.982222</td>\n",
       "      <td>200.968889</td>\n",
       "      <td>2465.004444</td>\n",
       "      <td>960.871111</td>\n",
       "      <td>122241.0844</td>\n",
       "      <td>431.164444</td>\n",
       "      <td>24.977778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390.408889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5156.524444</td>\n",
       "      <td>4880.293333</td>\n",
       "      <td>1835.742222</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>5826.880000</td>\n",
       "      <td>149.813333</td>\n",
       "      <td>1121.991111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8911.973333</td>\n",
       "      <td>139.751111</td>\n",
       "      <td>273.537778</td>\n",
       "      <td>1968.320000</td>\n",
       "      <td>833.466667</td>\n",
       "      <td>123267.3867</td>\n",
       "      <td>403.288889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>519.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3845.191111</td>\n",
       "      <td>663.422222</td>\n",
       "      <td>1808.435556</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>2657.511111</td>\n",
       "      <td>133.413333</td>\n",
       "      <td>1038.924444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9549.253333</td>\n",
       "      <td>46.835556</td>\n",
       "      <td>254.151111</td>\n",
       "      <td>2169.271111</td>\n",
       "      <td>930.284444</td>\n",
       "      <td>119550.0000</td>\n",
       "      <td>351.555556</td>\n",
       "      <td>2.622222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.128889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1243.200000</td>\n",
       "      <td>372.400000</td>\n",
       "      <td>2171.164444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2533.546667</td>\n",
       "      <td>300.497778</td>\n",
       "      <td>1237.626667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8818.835556</td>\n",
       "      <td>146.008889</td>\n",
       "      <td>370.248889</td>\n",
       "      <td>2705.857778</td>\n",
       "      <td>937.822222</td>\n",
       "      <td>117472.8622</td>\n",
       "      <td>56.648889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1    2            3            4            5          6    \\\n",
       "2137  0.0  2152.924444  0.0  1847.493333   210.124444  1237.360000  68.746667   \n",
       "2138  0.0  1030.453333  0.0  4569.946667  1531.866667  1965.822222   1.475556   \n",
       "2139  0.0   390.408889  0.0  5156.524444  4880.293333  1835.742222   0.862222   \n",
       "2140  0.0   519.155556  0.0  3845.191111   663.422222  1808.435556   0.391111   \n",
       "2141  0.0  1131.128889  0.0  1243.200000   372.400000  2171.164444   0.426667   \n",
       "\n",
       "              7           8            9    ...  519          520         521  \\\n",
       "2137  4979.697778  116.871111  1229.848889  ...  0.0  9318.675556   66.871111   \n",
       "2138  5078.666667  157.457778   960.746667  ...  0.0  9558.613333   77.982222   \n",
       "2139  5826.880000  149.813333  1121.991111  ...  0.0  8911.973333  139.751111   \n",
       "2140  2657.511111  133.413333  1038.924444  ...  0.0  9549.253333   46.835556   \n",
       "2141  2533.546667  300.497778  1237.626667  ...  0.0  8818.835556  146.008889   \n",
       "\n",
       "             522          523         524          525         526        527  \\\n",
       "2137  482.311111  2329.564444  878.035556  119879.8844  249.440000  37.022222   \n",
       "2138  200.968889  2465.004444  960.871111  122241.0844  431.164444  24.977778   \n",
       "2139  273.537778  1968.320000  833.466667  123267.3867  403.288889   0.000000   \n",
       "2140  254.151111  2169.271111  930.284444  119550.0000  351.555556   2.622222   \n",
       "2141  370.248889  2705.857778  937.822222  117472.8622   56.648889   0.000000   \n",
       "\n",
       "      528  \n",
       "2137  0.0  \n",
       "2138  0.0  \n",
       "2139  0.0  \n",
       "2140  0.0  \n",
       "2141  0.0  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_inverse_verif=sc.inverse_transform(y_test)\n",
    "y_test_inverse_verif=pd.DataFrame(y_test_inverse_verif)\n",
    "y_test_inverse_verif.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape (8603, 12, 529)\n",
      "x_test_shape (2142, 12, 529)\n",
      "y_train (8603, 529)\n",
      "y_test (2142, 529)\n",
      "n_feature 529\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train_shape\", x_train.shape)\n",
    "print(\"x_test_shape\", x_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "print(\"n_feature\", x_train.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (8603, 1000)              4120000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (8603, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (8603, 529)               529529    \n",
      "=================================================================\n",
      "Total params: 4,649,529\n",
      "Trainable params: 4,649,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "d = 0.5\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units=500, input_shape=(x_train.shape[1], x_train.shape[2]), activation=\"relu\")))#, return_sequences=True))\n",
    "model.add(Dropout(d))\n",
    "#model.add(LSTM(units=500, activation=\"relu\"))\n",
    "#model.add(Dropout(d))\n",
    "#model.add(keras.layers.Dropout(rate=0))\n",
    "#model.add(LSTM(units=300, activation=\"relu\"))\n",
    "#model.add(Dropout(d))\n",
    "model.add(Dense(units=529))\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "model.build(input_shape = (x_train.shape[0],12,529))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 3/1000\n",
      "242/242 [==============================] - 37s 153ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 4/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 5/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 17/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 18/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 23/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 24/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 25/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 26/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 0.0011 - val_loss: 9.8888e-04\n",
      "Epoch 27/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0011 - val_loss: 9.9045e-04\n",
      "Epoch 28/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 29/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0011 - val_loss: 9.8431e-04\n",
      "Epoch 30/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0011 - val_loss: 9.7733e-04\n",
      "Epoch 31/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0011 - val_loss: 9.6684e-04\n",
      "Epoch 32/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0011 - val_loss: 9.6197e-04\n",
      "Epoch 33/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0010 - val_loss: 9.6529e-04\n",
      "Epoch 34/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 0.0010 - val_loss: 9.6115e-04\n",
      "Epoch 35/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0010 - val_loss: 9.6243e-04\n",
      "Epoch 36/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0010 - val_loss: 9.6319e-04\n",
      "Epoch 37/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0010 - val_loss: 9.4895e-04\n",
      "Epoch 38/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0010 - val_loss: 9.4750e-04\n",
      "Epoch 39/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 0.0010 - val_loss: 9.4058e-04\n",
      "Epoch 40/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 0.0010 - val_loss: 9.2744e-04\n",
      "Epoch 41/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.9823e-04 - val_loss: 9.2516e-04\n",
      "Epoch 42/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 9.9053e-04 - val_loss: 9.2731e-04\n",
      "Epoch 43/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.8239e-04 - val_loss: 9.2203e-04\n",
      "Epoch 44/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.7736e-04 - val_loss: 9.1985e-04\n",
      "Epoch 45/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.6949e-04 - val_loss: 9.2009e-04\n",
      "Epoch 46/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 9.6510e-04 - val_loss: 9.2321e-04\n",
      "Epoch 47/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.6164e-04 - val_loss: 9.2908e-04\n",
      "Epoch 48/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.5545e-04 - val_loss: 9.2567e-04\n",
      "Epoch 49/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.4745e-04 - val_loss: 9.3207e-04\n",
      "Epoch 50/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 9.4507e-04 - val_loss: 9.3693e-04\n",
      "Epoch 51/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.4302e-04 - val_loss: 9.2924e-04\n",
      "Epoch 52/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.4362e-04 - val_loss: 9.4004e-04\n",
      "Epoch 53/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.4312e-04 - val_loss: 9.4149e-04\n",
      "Epoch 54/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.4199e-04 - val_loss: 9.3214e-04\n",
      "Epoch 55/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 9.3786e-04 - val_loss: 9.0867e-04\n",
      "Epoch 56/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.3028e-04 - val_loss: 9.0343e-04\n",
      "Epoch 57/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.2911e-04 - val_loss: 9.0875e-04\n",
      "Epoch 58/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 9.3006e-04 - val_loss: 9.1417e-04\n",
      "Epoch 59/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 9.2599e-04 - val_loss: 9.1298e-04\n",
      "Epoch 60/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.1749e-04 - val_loss: 9.1366e-04\n",
      "Epoch 61/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.2585e-04 - val_loss: 9.0695e-04\n",
      "Epoch 62/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.1986e-04 - val_loss: 9.0766e-04\n",
      "Epoch 63/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.0440e-04 - val_loss: 9.3345e-04\n",
      "Epoch 64/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.1194e-04 - val_loss: 9.3298e-04\n",
      "Epoch 65/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 9.1656e-04 - val_loss: 9.3344e-04\n",
      "Epoch 66/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 9.0453e-04 - val_loss: 9.0903e-04\n",
      "Epoch 67/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.9635e-04 - val_loss: 8.9429e-04\n",
      "Epoch 68/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.9586e-04 - val_loss: 8.9173e-04\n",
      "Epoch 69/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.9412e-04 - val_loss: 9.0257e-04\n",
      "Epoch 70/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.8428e-04 - val_loss: 9.0362e-04\n",
      "Epoch 71/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.8821e-04 - val_loss: 8.9931e-04\n",
      "Epoch 72/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.8403e-04 - val_loss: 8.9458e-04\n",
      "Epoch 73/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.7838e-04 - val_loss: 9.0449e-04\n",
      "Epoch 74/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.7579e-04 - val_loss: 9.2128e-04\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 158ms/step - loss: 8.8344e-04 - val_loss: 9.1888e-04\n",
      "Epoch 76/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.7667e-04 - val_loss: 9.2319e-04\n",
      "Epoch 77/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.7460e-04 - val_loss: 8.9579e-04\n",
      "Epoch 78/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.7262e-04 - val_loss: 8.8989e-04\n",
      "Epoch 79/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.6296e-04 - val_loss: 8.8825e-04\n",
      "Epoch 80/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.6852e-04 - val_loss: 8.8959e-04\n",
      "Epoch 81/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.6895e-04 - val_loss: 8.8636e-04\n",
      "Epoch 82/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.6122e-04 - val_loss: 8.9269e-04\n",
      "Epoch 83/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.5373e-04 - val_loss: 8.9681e-04\n",
      "Epoch 84/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.5810e-04 - val_loss: 9.0066e-04\n",
      "Epoch 85/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.5140e-04 - val_loss: 9.1012e-04\n",
      "Epoch 86/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.5137e-04 - val_loss: 9.1166e-04\n",
      "Epoch 87/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4436e-04 - val_loss: 8.9328e-04\n",
      "Epoch 88/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4296e-04 - val_loss: 8.9539e-04\n",
      "Epoch 89/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4506e-04 - val_loss: 8.9166e-04\n",
      "Epoch 90/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4837e-04 - val_loss: 8.8544e-04\n",
      "Epoch 91/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.4484e-04 - val_loss: 8.9231e-04\n",
      "Epoch 92/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4466e-04 - val_loss: 8.8850e-04\n",
      "Epoch 93/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4101e-04 - val_loss: 8.8741e-04\n",
      "Epoch 94/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4195e-04 - val_loss: 8.8550e-04\n",
      "Epoch 95/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.3713e-04 - val_loss: 8.9183e-04\n",
      "Epoch 96/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.3445e-04 - val_loss: 9.0737e-04\n",
      "Epoch 97/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.4669e-04 - val_loss: 9.2237e-04\n",
      "Epoch 98/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.3825e-04 - val_loss: 9.0177e-04\n",
      "Epoch 99/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.4025e-04 - val_loss: 8.9256e-04\n",
      "Epoch 100/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.2851e-04 - val_loss: 8.8306e-04\n",
      "Epoch 101/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1868e-04 - val_loss: 8.8223e-04\n",
      "Epoch 102/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.2290e-04 - val_loss: 8.8902e-04\n",
      "Epoch 103/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.3308e-04 - val_loss: 8.8550e-04\n",
      "Epoch 104/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1809e-04 - val_loss: 8.9298e-04\n",
      "Epoch 105/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.2622e-04 - val_loss: 8.9473e-04\n",
      "Epoch 106/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0907e-04 - val_loss: 9.0445e-04\n",
      "Epoch 107/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.2140e-04 - val_loss: 9.0443e-04\n",
      "Epoch 108/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.3813e-04 - val_loss: 9.0144e-04\n",
      "Epoch 109/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.2357e-04 - val_loss: 9.0119e-04\n",
      "Epoch 110/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1668e-04 - val_loss: 8.9277e-04\n",
      "Epoch 111/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1558e-04 - val_loss: 8.8931e-04\n",
      "Epoch 112/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0869e-04 - val_loss: 8.8434e-04\n",
      "Epoch 113/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 8.1734e-04 - val_loss: 8.8199e-04\n",
      "Epoch 114/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1559e-04 - val_loss: 8.8201e-04\n",
      "Epoch 115/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 8.1317e-04 - val_loss: 8.8334e-04\n",
      "Epoch 116/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0284e-04 - val_loss: 8.9317e-04\n",
      "Epoch 117/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.9490e-04 - val_loss: 8.9434e-04\n",
      "Epoch 118/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0627e-04 - val_loss: 8.9363e-04\n",
      "Epoch 119/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1015e-04 - val_loss: 8.8964e-04\n",
      "Epoch 120/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.1019e-04 - val_loss: 8.8928e-04\n",
      "Epoch 121/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0986e-04 - val_loss: 8.8812e-04\n",
      "Epoch 122/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0181e-04 - val_loss: 8.9062e-04\n",
      "Epoch 123/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 8.0300e-04 - val_loss: 8.8128e-04\n",
      "Epoch 124/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.9805e-04 - val_loss: 8.8320e-04\n",
      "Epoch 125/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0227e-04 - val_loss: 8.8318e-04\n",
      "Epoch 126/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 8.0568e-04 - val_loss: 8.9228e-04\n",
      "Epoch 127/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.9922e-04 - val_loss: 8.9021e-04\n",
      "Epoch 128/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.8687e-04 - val_loss: 8.8841e-04\n",
      "Epoch 129/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.0311e-04 - val_loss: 8.9129e-04\n",
      "Epoch 130/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.8188e-04 - val_loss: 8.9656e-04\n",
      "Epoch 131/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 7.9516e-04 - val_loss: 8.8625e-04\n",
      "Epoch 132/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 8.0050e-04 - val_loss: 8.9379e-04\n",
      "Epoch 133/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.0433e-04 - val_loss: 8.8946e-04\n",
      "Epoch 134/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.8158e-04 - val_loss: 8.8529e-04\n",
      "Epoch 135/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 8.0444e-04 - val_loss: 8.8137e-04\n",
      "Epoch 136/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 7.8353e-04 - val_loss: 8.8436e-04\n",
      "Epoch 137/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 8.0284e-04 - val_loss: 8.9934e-04\n",
      "Epoch 138/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.1350e-04 - val_loss: 8.8910e-04\n",
      "Epoch 139/1000\n",
      "242/242 [==============================] - 40s 167ms/step - loss: 7.8699e-04 - val_loss: 8.8313e-04\n",
      "Epoch 140/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 7.7211e-04 - val_loss: 8.8635e-04\n",
      "Epoch 141/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 8.0065e-04 - val_loss: 8.9111e-04\n",
      "Epoch 142/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.8885e-04 - val_loss: 8.9455e-04\n",
      "Epoch 143/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.8663e-04 - val_loss: 8.8843e-04\n",
      "Epoch 144/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.7215e-04 - val_loss: 8.8664e-04\n",
      "Epoch 145/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.8056e-04 - val_loss: 8.8367e-04\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 158ms/step - loss: 7.6459e-04 - val_loss: 8.8038e-04\n",
      "Epoch 147/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 7.7149e-04 - val_loss: 8.8653e-04\n",
      "Epoch 148/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7775e-04 - val_loss: 8.8966e-04\n",
      "Epoch 149/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.8732e-04 - val_loss: 8.8197e-04\n",
      "Epoch 150/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.7782e-04 - val_loss: 8.8325e-04\n",
      "Epoch 151/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7440e-04 - val_loss: 8.9215e-04\n",
      "Epoch 152/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 7.8751e-04 - val_loss: 9.1631e-04\n",
      "Epoch 153/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6999e-04 - val_loss: 8.8809e-04\n",
      "Epoch 154/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 7.8391e-04 - val_loss: 8.9308e-04\n",
      "Epoch 155/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7866e-04 - val_loss: 8.8326e-04\n",
      "Epoch 156/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.8125e-04 - val_loss: 8.8327e-04\n",
      "Epoch 157/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 7.7140e-04 - val_loss: 8.8666e-04\n",
      "Epoch 158/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5980e-04 - val_loss: 8.8209e-04\n",
      "Epoch 159/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5578e-04 - val_loss: 8.8368e-04\n",
      "Epoch 160/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4752e-04 - val_loss: 8.7926e-04\n",
      "Epoch 161/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5501e-04 - val_loss: 8.9132e-04\n",
      "Epoch 162/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6414e-04 - val_loss: 8.9619e-04\n",
      "Epoch 163/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7638e-04 - val_loss: 8.8863e-04\n",
      "Epoch 164/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 7.6105e-04 - val_loss: 8.8867e-04\n",
      "Epoch 165/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.7455e-04 - val_loss: 8.8197e-04\n",
      "Epoch 166/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6376e-04 - val_loss: 8.8419e-04\n",
      "Epoch 167/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7725e-04 - val_loss: 8.8185e-04\n",
      "Epoch 168/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5646e-04 - val_loss: 8.8294e-04\n",
      "Epoch 169/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5101e-04 - val_loss: 8.8779e-04\n",
      "Epoch 170/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5187e-04 - val_loss: 8.8944e-04\n",
      "Epoch 171/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4108e-04 - val_loss: 8.8595e-04\n",
      "Epoch 172/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 7.5106e-04 - val_loss: 8.9054e-04\n",
      "Epoch 173/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7521e-04 - val_loss: 8.9698e-04\n",
      "Epoch 174/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.9167e-04 - val_loss: 9.0103e-04\n",
      "Epoch 175/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.9049e-04 - val_loss: 8.9237e-04\n",
      "Epoch 176/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.7483e-04 - val_loss: 8.8452e-04\n",
      "Epoch 177/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6903e-04 - val_loss: 8.8279e-04\n",
      "Epoch 178/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6613e-04 - val_loss: 8.8444e-04\n",
      "Epoch 179/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4836e-04 - val_loss: 8.8337e-04\n",
      "Epoch 180/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.4764e-04 - val_loss: 8.8993e-04\n",
      "Epoch 181/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6019e-04 - val_loss: 8.8926e-04\n",
      "Epoch 182/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5987e-04 - val_loss: 8.9255e-04\n",
      "Epoch 183/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4663e-04 - val_loss: 8.9289e-04\n",
      "Epoch 184/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4202e-04 - val_loss: 8.9564e-04\n",
      "Epoch 185/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4353e-04 - val_loss: 8.9580e-04\n",
      "Epoch 186/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.5231e-04 - val_loss: 8.9374e-04\n",
      "Epoch 187/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6503e-04 - val_loss: 8.9304e-04\n",
      "Epoch 188/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.6030e-04 - val_loss: 8.8499e-04\n",
      "Epoch 189/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4079e-04 - val_loss: 8.8570e-04\n",
      "Epoch 190/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3759e-04 - val_loss: 8.8519e-04\n",
      "Epoch 191/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5921e-04 - val_loss: 8.9125e-04\n",
      "Epoch 192/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.5100e-04 - val_loss: 8.8655e-04\n",
      "Epoch 193/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4815e-04 - val_loss: 8.9430e-04\n",
      "Epoch 194/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3996e-04 - val_loss: 8.9125e-04\n",
      "Epoch 195/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4166e-04 - val_loss: 8.9757e-04\n",
      "Epoch 196/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.3672e-04 - val_loss: 8.9125e-04\n",
      "Epoch 197/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4724e-04 - val_loss: 8.8960e-04\n",
      "Epoch 198/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4775e-04 - val_loss: 8.8971e-04\n",
      "Epoch 199/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3403e-04 - val_loss: 8.8211e-04\n",
      "Epoch 200/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4176e-04 - val_loss: 8.8969e-04\n",
      "Epoch 201/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.6512e-04 - val_loss: 8.9356e-04\n",
      "Epoch 202/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 7.3778e-04 - val_loss: 8.9422e-04\n",
      "Epoch 203/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3374e-04 - val_loss: 9.1026e-04\n",
      "Epoch 204/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.4579e-04 - val_loss: 9.0940e-04\n",
      "Epoch 205/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4952e-04 - val_loss: 8.9653e-04\n",
      "Epoch 206/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3656e-04 - val_loss: 8.9713e-04\n",
      "Epoch 207/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4241e-04 - val_loss: 8.8727e-04\n",
      "Epoch 208/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2571e-04 - val_loss: 8.8570e-04\n",
      "Epoch 209/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2339e-04 - val_loss: 8.9166e-04\n",
      "Epoch 210/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1809e-04 - val_loss: 8.9481e-04\n",
      "Epoch 211/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4236e-04 - val_loss: 8.9376e-04\n",
      "Epoch 212/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 7.5129e-04 - val_loss: 8.9039e-04\n",
      "Epoch 213/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4049e-04 - val_loss: 8.9416e-04\n",
      "Epoch 214/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2993e-04 - val_loss: 8.9933e-04\n",
      "Epoch 215/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3009e-04 - val_loss: 8.9474e-04\n",
      "Epoch 216/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2066e-04 - val_loss: 8.9477e-04\n",
      "Epoch 217/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2328e-04 - val_loss: 8.8895e-04\n",
      "Epoch 218/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1037e-04 - val_loss: 8.8696e-04\n",
      "Epoch 219/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2232e-04 - val_loss: 8.9092e-04\n",
      "Epoch 220/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.4033e-04 - val_loss: 8.9662e-04\n",
      "Epoch 221/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.5199e-04 - val_loss: 8.8916e-04\n",
      "Epoch 222/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3399e-04 - val_loss: 8.9002e-04\n",
      "Epoch 223/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2129e-04 - val_loss: 8.9767e-04\n",
      "Epoch 224/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2325e-04 - val_loss: 9.0013e-04\n",
      "Epoch 225/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1551e-04 - val_loss: 9.0310e-04\n",
      "Epoch 226/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3165e-04 - val_loss: 8.9946e-04\n",
      "Epoch 227/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2173e-04 - val_loss: 8.9088e-04\n",
      "Epoch 228/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1267e-04 - val_loss: 8.8897e-04\n",
      "Epoch 229/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.0985e-04 - val_loss: 8.9015e-04\n",
      "Epoch 230/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1643e-04 - val_loss: 8.8973e-04\n",
      "Epoch 231/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3670e-04 - val_loss: 8.9423e-04\n",
      "Epoch 232/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3992e-04 - val_loss: 8.9669e-04\n",
      "Epoch 233/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2341e-04 - val_loss: 8.9262e-04\n",
      "Epoch 234/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2988e-04 - val_loss: 9.0409e-04\n",
      "Epoch 235/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3726e-04 - val_loss: 9.0111e-04\n",
      "Epoch 236/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2191e-04 - val_loss: 9.0285e-04\n",
      "Epoch 237/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.1396e-04 - val_loss: 8.9258e-04\n",
      "Epoch 238/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0733e-04 - val_loss: 8.9253e-04\n",
      "Epoch 239/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1836e-04 - val_loss: 8.9042e-04\n",
      "Epoch 240/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.0635e-04 - val_loss: 8.9051e-04\n",
      "Epoch 241/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1398e-04 - val_loss: 8.9079e-04\n",
      "Epoch 242/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1309e-04 - val_loss: 8.9745e-04\n",
      "Epoch 243/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2204e-04 - val_loss: 8.9425e-04\n",
      "Epoch 244/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0457e-04 - val_loss: 8.9672e-04\n",
      "Epoch 245/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 7.1115e-04 - val_loss: 8.9998e-04\n",
      "Epoch 246/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1447e-04 - val_loss: 9.1124e-04\n",
      "Epoch 247/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2198e-04 - val_loss: 8.9847e-04\n",
      "Epoch 248/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1586e-04 - val_loss: 8.9551e-04\n",
      "Epoch 249/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2468e-04 - val_loss: 8.9258e-04\n",
      "Epoch 250/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0135e-04 - val_loss: 8.9081e-04\n",
      "Epoch 251/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0669e-04 - val_loss: 8.8640e-04\n",
      "Epoch 252/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1034e-04 - val_loss: 8.9317e-04\n",
      "Epoch 253/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.0195e-04 - val_loss: 9.0375e-04\n",
      "Epoch 254/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9914e-04 - val_loss: 8.9929e-04\n",
      "Epoch 255/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3484e-04 - val_loss: 9.0320e-04\n",
      "Epoch 256/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2704e-04 - val_loss: 9.0185e-04\n",
      "Epoch 257/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2546e-04 - val_loss: 8.9256e-04\n",
      "Epoch 258/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1531e-04 - val_loss: 9.0003e-04\n",
      "Epoch 259/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.2434e-04 - val_loss: 8.9433e-04\n",
      "Epoch 260/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1341e-04 - val_loss: 8.9617e-04\n",
      "Epoch 261/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.2405e-04 - val_loss: 8.9249e-04\n",
      "Epoch 262/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0839e-04 - val_loss: 8.9129e-04\n",
      "Epoch 263/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0027e-04 - val_loss: 8.9704e-04\n",
      "Epoch 264/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.1599e-04 - val_loss: 9.0061e-04\n",
      "Epoch 265/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.9893e-04 - val_loss: 8.9496e-04\n",
      "Epoch 266/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9456e-04 - val_loss: 8.9638e-04\n",
      "Epoch 267/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 7.0153e-04 - val_loss: 8.9272e-04\n",
      "Epoch 268/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0154e-04 - val_loss: 8.9651e-04\n",
      "Epoch 269/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.0568e-04 - val_loss: 8.9594e-04\n",
      "Epoch 270/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.1398e-04 - val_loss: 8.9864e-04\n",
      "Epoch 271/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2219e-04 - val_loss: 8.9204e-04\n",
      "Epoch 272/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0230e-04 - val_loss: 8.9276e-04\n",
      "Epoch 273/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9296e-04 - val_loss: 8.9843e-04\n",
      "Epoch 274/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9836e-04 - val_loss: 8.9626e-04\n",
      "Epoch 275/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.3319e-04 - val_loss: 8.9951e-04\n",
      "Epoch 276/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2773e-04 - val_loss: 8.9875e-04\n",
      "Epoch 277/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.1515e-04 - val_loss: 8.9859e-04\n",
      "Epoch 278/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0024e-04 - val_loss: 9.0061e-04\n",
      "Epoch 279/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0069e-04 - val_loss: 8.9832e-04\n",
      "Epoch 280/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9659e-04 - val_loss: 8.9980e-04\n",
      "Epoch 281/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 7.0226e-04 - val_loss: 9.0285e-04\n",
      "Epoch 282/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8613e-04 - val_loss: 9.0501e-04\n",
      "Epoch 283/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8809e-04 - val_loss: 9.0588e-04\n",
      "Epoch 284/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9489e-04 - val_loss: 8.9979e-04\n",
      "Epoch 285/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 7.0221e-04 - val_loss: 8.9657e-04\n",
      "Epoch 286/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8989e-04 - val_loss: 9.0119e-04\n",
      "Epoch 287/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8397e-04 - val_loss: 9.0245e-04\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8428e-04 - val_loss: 8.9869e-04\n",
      "Epoch 289/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9567e-04 - val_loss: 9.0662e-04\n",
      "Epoch 290/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9955e-04 - val_loss: 9.0511e-04\n",
      "Epoch 291/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9382e-04 - val_loss: 8.9999e-04\n",
      "Epoch 292/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9574e-04 - val_loss: 9.1366e-04\n",
      "Epoch 293/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9380e-04 - val_loss: 9.1170e-04\n",
      "Epoch 294/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.9776e-04 - val_loss: 9.0249e-04\n",
      "Epoch 295/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8965e-04 - val_loss: 8.9651e-04\n",
      "Epoch 296/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9194e-04 - val_loss: 8.9935e-04\n",
      "Epoch 297/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8593e-04 - val_loss: 9.0051e-04\n",
      "Epoch 298/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9915e-04 - val_loss: 8.9556e-04\n",
      "Epoch 299/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.2146e-04 - val_loss: 9.0300e-04\n",
      "Epoch 300/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.1449e-04 - val_loss: 9.0457e-04\n",
      "Epoch 301/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.8813e-04 - val_loss: 9.0201e-04\n",
      "Epoch 302/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.8732e-04 - val_loss: 9.0483e-04\n",
      "Epoch 303/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9303e-04 - val_loss: 8.9942e-04\n",
      "Epoch 304/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0367e-04 - val_loss: 9.1274e-04\n",
      "Epoch 305/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9675e-04 - val_loss: 9.0538e-04\n",
      "Epoch 306/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.9141e-04 - val_loss: 9.0484e-04\n",
      "Epoch 307/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9090e-04 - val_loss: 9.0041e-04\n",
      "Epoch 308/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7421e-04 - val_loss: 9.0079e-04\n",
      "Epoch 309/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9134e-04 - val_loss: 9.0297e-04\n",
      "Epoch 310/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.7652e-04 - val_loss: 9.0427e-04\n",
      "Epoch 311/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7429e-04 - val_loss: 9.1431e-04\n",
      "Epoch 312/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.8371e-04 - val_loss: 9.0079e-04\n",
      "Epoch 313/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7804e-04 - val_loss: 9.1117e-04\n",
      "Epoch 314/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7950e-04 - val_loss: 9.0473e-04\n",
      "Epoch 315/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7818e-04 - val_loss: 8.9627e-04\n",
      "Epoch 316/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7713e-04 - val_loss: 9.0255e-04\n",
      "Epoch 317/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8215e-04 - val_loss: 9.0165e-04\n",
      "Epoch 318/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.9098e-04 - val_loss: 9.0815e-04\n",
      "Epoch 319/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9412e-04 - val_loss: 8.9781e-04\n",
      "Epoch 320/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0209e-04 - val_loss: 9.0089e-04\n",
      "Epoch 321/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7777e-04 - val_loss: 9.0274e-04\n",
      "Epoch 322/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8057e-04 - val_loss: 9.1287e-04\n",
      "Epoch 323/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7875e-04 - val_loss: 9.0745e-04\n",
      "Epoch 324/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8949e-04 - val_loss: 9.1815e-04\n",
      "Epoch 325/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9118e-04 - val_loss: 9.0331e-04\n",
      "Epoch 326/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.7772e-04 - val_loss: 9.0225e-04\n",
      "Epoch 327/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9356e-04 - val_loss: 9.0405e-04\n",
      "Epoch 328/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8734e-04 - val_loss: 9.0480e-04\n",
      "Epoch 329/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8440e-04 - val_loss: 9.0337e-04\n",
      "Epoch 330/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7859e-04 - val_loss: 8.9943e-04\n",
      "Epoch 331/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7337e-04 - val_loss: 9.0701e-04\n",
      "Epoch 332/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8157e-04 - val_loss: 9.1719e-04\n",
      "Epoch 333/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7614e-04 - val_loss: 9.1284e-04\n",
      "Epoch 334/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.9280e-04 - val_loss: 9.1280e-04\n",
      "Epoch 335/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.9508e-04 - val_loss: 9.1203e-04\n",
      "Epoch 336/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8714e-04 - val_loss: 9.0956e-04\n",
      "Epoch 337/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7482e-04 - val_loss: 9.0145e-04\n",
      "Epoch 338/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8042e-04 - val_loss: 9.0781e-04\n",
      "Epoch 339/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8220e-04 - val_loss: 9.0978e-04\n",
      "Epoch 340/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.7357e-04 - val_loss: 9.0572e-04\n",
      "Epoch 341/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7760e-04 - val_loss: 9.1020e-04\n",
      "Epoch 342/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.6960e-04 - val_loss: 9.1450e-04\n",
      "Epoch 343/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8089e-04 - val_loss: 9.2020e-04\n",
      "Epoch 344/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7706e-04 - val_loss: 9.1451e-04\n",
      "Epoch 345/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7266e-04 - val_loss: 9.0233e-04\n",
      "Epoch 346/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7518e-04 - val_loss: 9.0881e-04\n",
      "Epoch 347/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.9685e-04 - val_loss: 9.1997e-04\n",
      "Epoch 348/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8838e-04 - val_loss: 9.1275e-04\n",
      "Epoch 349/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8035e-04 - val_loss: 9.1446e-04\n",
      "Epoch 350/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.6669e-04 - val_loss: 9.0857e-04\n",
      "Epoch 351/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6537e-04 - val_loss: 9.1589e-04\n",
      "Epoch 352/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6316e-04 - val_loss: 9.1812e-04\n",
      "Epoch 353/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7047e-04 - val_loss: 9.1544e-04\n",
      "Epoch 354/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.7414e-04 - val_loss: 9.2072e-04\n",
      "Epoch 355/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8048e-04 - val_loss: 9.1921e-04\n",
      "Epoch 356/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7372e-04 - val_loss: 9.1281e-04\n",
      "Epoch 357/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7177e-04 - val_loss: 9.0954e-04\n",
      "Epoch 358/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6598e-04 - val_loss: 9.1257e-04\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8123e-04 - val_loss: 9.1663e-04\n",
      "Epoch 360/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7553e-04 - val_loss: 9.1243e-04\n",
      "Epoch 361/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.7148e-04 - val_loss: 9.1269e-04\n",
      "Epoch 362/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6865e-04 - val_loss: 9.1853e-04\n",
      "Epoch 363/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6617e-04 - val_loss: 9.2464e-04\n",
      "Epoch 364/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6041e-04 - val_loss: 9.1923e-04\n",
      "Epoch 365/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6518e-04 - val_loss: 9.1758e-04\n",
      "Epoch 366/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6623e-04 - val_loss: 9.1857e-04\n",
      "Epoch 367/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.7251e-04 - val_loss: 9.1358e-04\n",
      "Epoch 368/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6550e-04 - val_loss: 9.1694e-04\n",
      "Epoch 369/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6686e-04 - val_loss: 9.1151e-04\n",
      "Epoch 370/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7540e-04 - val_loss: 9.1505e-04\n",
      "Epoch 371/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6927e-04 - val_loss: 9.1760e-04\n",
      "Epoch 372/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6195e-04 - val_loss: 9.1893e-04\n",
      "Epoch 373/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6271e-04 - val_loss: 9.2942e-04\n",
      "Epoch 374/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6085e-04 - val_loss: 9.2050e-04\n",
      "Epoch 375/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.5932e-04 - val_loss: 9.1265e-04\n",
      "Epoch 376/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7239e-04 - val_loss: 9.1322e-04\n",
      "Epoch 377/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5950e-04 - val_loss: 9.1607e-04\n",
      "Epoch 378/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.4285e-04 - val_loss: 9.1496e-04\n",
      "Epoch 379/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.8988e-04 - val_loss: 9.1816e-04\n",
      "Epoch 380/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6449e-04 - val_loss: 9.2868e-04\n",
      "Epoch 381/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6651e-04 - val_loss: 9.2901e-04\n",
      "Epoch 382/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6858e-04 - val_loss: 9.2278e-04\n",
      "Epoch 383/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.5744e-04 - val_loss: 9.1774e-04\n",
      "Epoch 384/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6636e-04 - val_loss: 9.1808e-04\n",
      "Epoch 385/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5881e-04 - val_loss: 9.1889e-04\n",
      "Epoch 386/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6574e-04 - val_loss: 9.1357e-04\n",
      "Epoch 387/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6836e-04 - val_loss: 9.1425e-04\n",
      "Epoch 388/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6753e-04 - val_loss: 9.1015e-04\n",
      "Epoch 389/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5937e-04 - val_loss: 9.1238e-04\n",
      "Epoch 390/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5765e-04 - val_loss: 9.2102e-04\n",
      "Epoch 391/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.6275e-04 - val_loss: 9.3663e-04\n",
      "Epoch 392/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6701e-04 - val_loss: 9.2662e-04\n",
      "Epoch 393/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6882e-04 - val_loss: 9.2157e-04\n",
      "Epoch 394/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5599e-04 - val_loss: 9.1828e-04\n",
      "Epoch 395/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6053e-04 - val_loss: 9.2765e-04\n",
      "Epoch 396/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5358e-04 - val_loss: 9.2359e-04\n",
      "Epoch 397/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5487e-04 - val_loss: 9.1757e-04\n",
      "Epoch 398/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7118e-04 - val_loss: 9.1965e-04\n",
      "Epoch 399/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.7980e-04 - val_loss: 9.1687e-04\n",
      "Epoch 400/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6519e-04 - val_loss: 9.3238e-04\n",
      "Epoch 401/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6324e-04 - val_loss: 9.2161e-04\n",
      "Epoch 402/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5859e-04 - val_loss: 9.3633e-04\n",
      "Epoch 403/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5183e-04 - val_loss: 9.2472e-04\n",
      "Epoch 404/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5240e-04 - val_loss: 9.2661e-04\n",
      "Epoch 405/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5597e-04 - val_loss: 9.2093e-04\n",
      "Epoch 406/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5033e-04 - val_loss: 9.2522e-04\n",
      "Epoch 407/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.5873e-04 - val_loss: 9.2271e-04\n",
      "Epoch 408/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.5152e-04 - val_loss: 9.2112e-04\n",
      "Epoch 409/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.5245e-04 - val_loss: 9.2054e-04\n",
      "Epoch 410/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.4937e-04 - val_loss: 9.2758e-04\n",
      "Epoch 411/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6846e-04 - val_loss: 9.2321e-04\n",
      "Epoch 412/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5280e-04 - val_loss: 9.3244e-04\n",
      "Epoch 413/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5205e-04 - val_loss: 9.1911e-04\n",
      "Epoch 414/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.4819e-04 - val_loss: 9.3051e-04\n",
      "Epoch 415/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.5363e-04 - val_loss: 9.2900e-04\n",
      "Epoch 416/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5571e-04 - val_loss: 9.2985e-04\n",
      "Epoch 417/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5287e-04 - val_loss: 9.1861e-04\n",
      "Epoch 418/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.8107e-04 - val_loss: 9.2036e-04\n",
      "Epoch 419/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6051e-04 - val_loss: 9.2257e-04\n",
      "Epoch 420/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5119e-04 - val_loss: 9.2391e-04\n",
      "Epoch 421/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5653e-04 - val_loss: 9.3223e-04\n",
      "Epoch 422/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.4776e-04 - val_loss: 9.4168e-04\n",
      "Epoch 423/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.5260e-04 - val_loss: 9.3293e-04\n",
      "Epoch 424/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4644e-04 - val_loss: 9.2765e-04\n",
      "Epoch 425/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.4949e-04 - val_loss: 9.2457e-04\n",
      "Epoch 426/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4727e-04 - val_loss: 9.2157e-04\n",
      "Epoch 427/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5261e-04 - val_loss: 9.2739e-04\n",
      "Epoch 428/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.6389e-04 - val_loss: 9.2538e-04\n",
      "Epoch 429/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5875e-04 - val_loss: 9.1880e-04\n",
      "Epoch 430/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6699e-04 - val_loss: 9.3386e-04\n",
      "Epoch 431/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.4922e-04 - val_loss: 9.2614e-04\n",
      "Epoch 432/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5285e-04 - val_loss: 9.3462e-04\n",
      "Epoch 433/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4737e-04 - val_loss: 9.2760e-04\n",
      "Epoch 434/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4734e-04 - val_loss: 9.3163e-04\n",
      "Epoch 435/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6938e-04 - val_loss: 9.2804e-04\n",
      "Epoch 436/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 7.0135e-04 - val_loss: 9.2798e-04\n",
      "Epoch 437/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5805e-04 - val_loss: 9.2482e-04\n",
      "Epoch 438/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4446e-04 - val_loss: 9.2646e-04\n",
      "Epoch 439/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4503e-04 - val_loss: 9.2679e-04\n",
      "Epoch 440/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.4579e-04 - val_loss: 9.3838e-04\n",
      "Epoch 441/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3978e-04 - val_loss: 9.2984e-04\n",
      "Epoch 442/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4310e-04 - val_loss: 9.3128e-04\n",
      "Epoch 443/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3870e-04 - val_loss: 9.2793e-04\n",
      "Epoch 444/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4438e-04 - val_loss: 9.2721e-04\n",
      "Epoch 445/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.5593e-04 - val_loss: 9.2979e-04\n",
      "Epoch 446/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4718e-04 - val_loss: 9.3108e-04\n",
      "Epoch 447/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4178e-04 - val_loss: 9.3828e-04\n",
      "Epoch 448/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.3972e-04 - val_loss: 9.2937e-04\n",
      "Epoch 449/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.5136e-04 - val_loss: 9.3343e-04\n",
      "Epoch 450/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4098e-04 - val_loss: 9.3601e-04\n",
      "Epoch 451/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5370e-04 - val_loss: 9.3447e-04\n",
      "Epoch 452/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6071e-04 - val_loss: 9.2535e-04\n",
      "Epoch 453/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5192e-04 - val_loss: 9.2116e-04\n",
      "Epoch 454/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5194e-04 - val_loss: 9.2620e-04\n",
      "Epoch 455/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4144e-04 - val_loss: 9.3018e-04\n",
      "Epoch 456/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 6.4387e-04 - val_loss: 9.2657e-04\n",
      "Epoch 457/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.6069e-04 - val_loss: 9.4025e-04\n",
      "Epoch 458/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.6387e-04 - val_loss: 9.4316e-04\n",
      "Epoch 459/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5426e-04 - val_loss: 9.3210e-04\n",
      "Epoch 460/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5126e-04 - val_loss: 9.3465e-04\n",
      "Epoch 461/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.4051e-04 - val_loss: 9.2748e-04\n",
      "Epoch 462/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3386e-04 - val_loss: 9.2922e-04\n",
      "Epoch 463/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4066e-04 - val_loss: 9.3425e-04\n",
      "Epoch 464/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.4303e-04 - val_loss: 9.2728e-04\n",
      "Epoch 465/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3984e-04 - val_loss: 9.2952e-04\n",
      "Epoch 466/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3842e-04 - val_loss: 9.3470e-04\n",
      "Epoch 467/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4758e-04 - val_loss: 9.3671e-04\n",
      "Epoch 468/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3789e-04 - val_loss: 9.3277e-04\n",
      "Epoch 469/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3642e-04 - val_loss: 9.3576e-04\n",
      "Epoch 470/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4790e-04 - val_loss: 9.4320e-04\n",
      "Epoch 471/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4565e-04 - val_loss: 9.4462e-04\n",
      "Epoch 472/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.3870e-04 - val_loss: 9.3443e-04\n",
      "Epoch 473/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5000e-04 - val_loss: 9.3065e-04\n",
      "Epoch 474/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.4319e-04 - val_loss: 9.3247e-04\n",
      "Epoch 475/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4702e-04 - val_loss: 9.2907e-04\n",
      "Epoch 476/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4080e-04 - val_loss: 9.3486e-04\n",
      "Epoch 477/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4872e-04 - val_loss: 9.5288e-04\n",
      "Epoch 478/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4893e-04 - val_loss: 9.4851e-04\n",
      "Epoch 479/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3658e-04 - val_loss: 9.3922e-04\n",
      "Epoch 480/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.3589e-04 - val_loss: 9.3500e-04\n",
      "Epoch 481/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4300e-04 - val_loss: 9.3622e-04\n",
      "Epoch 482/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4331e-04 - val_loss: 9.3756e-04\n",
      "Epoch 483/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4304e-04 - val_loss: 9.3976e-04\n",
      "Epoch 484/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3289e-04 - val_loss: 9.3756e-04\n",
      "Epoch 485/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3230e-04 - val_loss: 9.3584e-04\n",
      "Epoch 486/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.4780e-04 - val_loss: 9.5503e-04\n",
      "Epoch 487/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5461e-04 - val_loss: 9.3359e-04\n",
      "Epoch 488/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 6.4736e-04 - val_loss: 9.3255e-04\n",
      "Epoch 489/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4088e-04 - val_loss: 9.3989e-04\n",
      "Epoch 490/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3616e-04 - val_loss: 9.4396e-04\n",
      "Epoch 491/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3594e-04 - val_loss: 9.4710e-04\n",
      "Epoch 492/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3760e-04 - val_loss: 9.4025e-04\n",
      "Epoch 493/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.4268e-04 - val_loss: 9.4009e-04\n",
      "Epoch 494/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3742e-04 - val_loss: 9.5992e-04\n",
      "Epoch 495/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4689e-04 - val_loss: 9.4104e-04\n",
      "Epoch 496/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.3223e-04 - val_loss: 9.3275e-04\n",
      "Epoch 497/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2482e-04 - val_loss: 9.3147e-04\n",
      "Epoch 498/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2836e-04 - val_loss: 9.3330e-04\n",
      "Epoch 499/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3364e-04 - val_loss: 9.3535e-04\n",
      "Epoch 500/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4639e-04 - val_loss: 9.4843e-04\n",
      "Epoch 501/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 6.5089e-04 - val_loss: 9.5498e-04\n",
      "Epoch 502/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.3155e-04 - val_loss: 9.5166e-04\n",
      "Epoch 503/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3595e-04 - val_loss: 9.5209e-04\n",
      "Epoch 504/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.3661e-04 - val_loss: 9.4876e-04\n",
      "Epoch 505/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.3913e-04 - val_loss: 9.3875e-04\n",
      "Epoch 506/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.3438e-04 - val_loss: 9.3443e-04\n",
      "Epoch 507/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2762e-04 - val_loss: 9.3428e-04\n",
      "Epoch 508/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3242e-04 - val_loss: 9.3568e-04\n",
      "Epoch 509/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4096e-04 - val_loss: 9.3563e-04\n",
      "Epoch 510/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3349e-04 - val_loss: 9.4677e-04\n",
      "Epoch 511/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3517e-04 - val_loss: 9.6034e-04\n",
      "Epoch 512/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.3407e-04 - val_loss: 9.4530e-04\n",
      "Epoch 513/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.2640e-04 - val_loss: 9.4345e-04\n",
      "Epoch 514/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3259e-04 - val_loss: 9.4829e-04\n",
      "Epoch 515/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3354e-04 - val_loss: 9.4406e-04\n",
      "Epoch 516/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2746e-04 - val_loss: 9.3414e-04\n",
      "Epoch 517/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3750e-04 - val_loss: 9.3589e-04\n",
      "Epoch 518/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.3409e-04 - val_loss: 9.4249e-04\n",
      "Epoch 519/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4316e-04 - val_loss: 9.4574e-04\n",
      "Epoch 520/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3239e-04 - val_loss: 9.5065e-04\n",
      "Epoch 521/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.3124e-04 - val_loss: 9.4213e-04\n",
      "Epoch 522/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2573e-04 - val_loss: 9.4566e-04\n",
      "Epoch 523/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2748e-04 - val_loss: 9.4634e-04\n",
      "Epoch 524/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3105e-04 - val_loss: 9.5761e-04\n",
      "Epoch 525/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2699e-04 - val_loss: 9.5010e-04\n",
      "Epoch 526/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2757e-04 - val_loss: 9.3989e-04\n",
      "Epoch 527/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2187e-04 - val_loss: 9.4448e-04\n",
      "Epoch 528/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2652e-04 - val_loss: 9.3946e-04\n",
      "Epoch 529/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.3127e-04 - val_loss: 9.4109e-04\n",
      "Epoch 530/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2265e-04 - val_loss: 9.4144e-04\n",
      "Epoch 531/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2360e-04 - val_loss: 9.4373e-04\n",
      "Epoch 532/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2821e-04 - val_loss: 9.4295e-04\n",
      "Epoch 533/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3008e-04 - val_loss: 9.4279e-04\n",
      "Epoch 534/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2833e-04 - val_loss: 9.4937e-04\n",
      "Epoch 535/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2985e-04 - val_loss: 9.6159e-04\n",
      "Epoch 536/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3392e-04 - val_loss: 9.5329e-04\n",
      "Epoch 537/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2884e-04 - val_loss: 9.5079e-04\n",
      "Epoch 538/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3228e-04 - val_loss: 9.4507e-04\n",
      "Epoch 539/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4232e-04 - val_loss: 9.4895e-04\n",
      "Epoch 540/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2364e-04 - val_loss: 9.5938e-04\n",
      "Epoch 541/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3099e-04 - val_loss: 9.5423e-04\n",
      "Epoch 542/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2174e-04 - val_loss: 9.4824e-04\n",
      "Epoch 543/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.5047e-04 - val_loss: 9.4689e-04\n",
      "Epoch 544/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.3795e-04 - val_loss: 9.4246e-04\n",
      "Epoch 545/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2887e-04 - val_loss: 9.5646e-04\n",
      "Epoch 546/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3280e-04 - val_loss: 9.4971e-04\n",
      "Epoch 547/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2363e-04 - val_loss: 9.4912e-04\n",
      "Epoch 548/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2725e-04 - val_loss: 9.5797e-04\n",
      "Epoch 549/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3148e-04 - val_loss: 9.4213e-04\n",
      "Epoch 550/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2004e-04 - val_loss: 9.4373e-04\n",
      "Epoch 551/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.2179e-04 - val_loss: 9.4907e-04\n",
      "Epoch 552/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2362e-04 - val_loss: 9.4887e-04\n",
      "Epoch 553/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2214e-04 - val_loss: 9.5207e-04\n",
      "Epoch 554/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2631e-04 - val_loss: 9.4734e-04\n",
      "Epoch 555/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2037e-04 - val_loss: 9.5056e-04\n",
      "Epoch 556/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2774e-04 - val_loss: 9.5136e-04\n",
      "Epoch 557/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2551e-04 - val_loss: 9.5152e-04\n",
      "Epoch 558/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2850e-04 - val_loss: 9.5884e-04\n",
      "Epoch 559/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2724e-04 - val_loss: 9.4797e-04\n",
      "Epoch 560/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3512e-04 - val_loss: 9.5296e-04\n",
      "Epoch 561/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2082e-04 - val_loss: 9.4646e-04\n",
      "Epoch 562/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2073e-04 - val_loss: 9.4726e-04\n",
      "Epoch 563/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2380e-04 - val_loss: 9.4441e-04\n",
      "Epoch 564/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2527e-04 - val_loss: 9.4738e-04\n",
      "Epoch 565/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2635e-04 - val_loss: 9.5314e-04\n",
      "Epoch 566/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2595e-04 - val_loss: 9.5613e-04\n",
      "Epoch 567/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2430e-04 - val_loss: 9.4899e-04\n",
      "Epoch 568/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2829e-04 - val_loss: 9.5199e-04\n",
      "Epoch 569/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2051e-04 - val_loss: 9.4550e-04\n",
      "Epoch 570/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1582e-04 - val_loss: 9.5852e-04\n",
      "Epoch 571/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.1838e-04 - val_loss: 9.5375e-04\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2120e-04 - val_loss: 9.5228e-04\n",
      "Epoch 573/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2439e-04 - val_loss: 9.5102e-04\n",
      "Epoch 574/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2103e-04 - val_loss: 9.5023e-04\n",
      "Epoch 575/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2492e-04 - val_loss: 9.5589e-04\n",
      "Epoch 576/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1785e-04 - val_loss: 9.5600e-04\n",
      "Epoch 577/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.4168e-04 - val_loss: 9.5242e-04\n",
      "Epoch 578/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1750e-04 - val_loss: 9.4887e-04\n",
      "Epoch 579/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2408e-04 - val_loss: 9.5034e-04\n",
      "Epoch 580/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2037e-04 - val_loss: 9.5323e-04\n",
      "Epoch 581/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.7029e-04 - val_loss: 9.5681e-04\n",
      "Epoch 582/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3167e-04 - val_loss: 9.4786e-04\n",
      "Epoch 583/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2079e-04 - val_loss: 9.5333e-04\n",
      "Epoch 584/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1933e-04 - val_loss: 9.6875e-04\n",
      "Epoch 585/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.1416e-04 - val_loss: 9.6012e-04\n",
      "Epoch 586/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1655e-04 - val_loss: 9.5346e-04\n",
      "Epoch 587/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.3161e-04 - val_loss: 9.6195e-04\n",
      "Epoch 588/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2008e-04 - val_loss: 9.5241e-04\n",
      "Epoch 589/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3128e-04 - val_loss: 9.5334e-04\n",
      "Epoch 590/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2004e-04 - val_loss: 9.5079e-04\n",
      "Epoch 591/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1933e-04 - val_loss: 9.6205e-04\n",
      "Epoch 592/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2832e-04 - val_loss: 9.5407e-04\n",
      "Epoch 593/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2156e-04 - val_loss: 9.5477e-04\n",
      "Epoch 594/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1473e-04 - val_loss: 9.5191e-04\n",
      "Epoch 595/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1925e-04 - val_loss: 9.6404e-04\n",
      "Epoch 596/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2713e-04 - val_loss: 9.7112e-04\n",
      "Epoch 597/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1939e-04 - val_loss: 9.6314e-04\n",
      "Epoch 598/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1891e-04 - val_loss: 9.6136e-04\n",
      "Epoch 599/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2535e-04 - val_loss: 9.5273e-04\n",
      "Epoch 600/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1034e-04 - val_loss: 9.5902e-04\n",
      "Epoch 601/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.1535e-04 - val_loss: 9.6804e-04\n",
      "Epoch 602/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1253e-04 - val_loss: 9.6230e-04\n",
      "Epoch 603/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1968e-04 - val_loss: 9.5737e-04\n",
      "Epoch 604/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2047e-04 - val_loss: 9.4960e-04\n",
      "Epoch 605/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1722e-04 - val_loss: 9.6119e-04\n",
      "Epoch 606/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1885e-04 - val_loss: 9.5794e-04\n",
      "Epoch 607/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.1811e-04 - val_loss: 9.6242e-04\n",
      "Epoch 608/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1622e-04 - val_loss: 9.6550e-04\n",
      "Epoch 609/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.3431e-04 - val_loss: 9.6314e-04\n",
      "Epoch 610/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1416e-04 - val_loss: 9.5886e-04\n",
      "Epoch 611/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2150e-04 - val_loss: 9.5511e-04\n",
      "Epoch 612/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.1261e-04 - val_loss: 9.5721e-04\n",
      "Epoch 613/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0632e-04 - val_loss: 9.5228e-04\n",
      "Epoch 614/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1801e-04 - val_loss: 9.5579e-04\n",
      "Epoch 615/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1078e-04 - val_loss: 9.5429e-04\n",
      "Epoch 616/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1407e-04 - val_loss: 9.5463e-04\n",
      "Epoch 617/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1405e-04 - val_loss: 9.6112e-04\n",
      "Epoch 618/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0864e-04 - val_loss: 9.5846e-04\n",
      "Epoch 619/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1586e-04 - val_loss: 9.7493e-04\n",
      "Epoch 620/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1970e-04 - val_loss: 9.6190e-04\n",
      "Epoch 621/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1015e-04 - val_loss: 9.6860e-04\n",
      "Epoch 622/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1415e-04 - val_loss: 9.5460e-04\n",
      "Epoch 623/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0857e-04 - val_loss: 9.6424e-04\n",
      "Epoch 624/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0896e-04 - val_loss: 9.5695e-04\n",
      "Epoch 625/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1705e-04 - val_loss: 9.6374e-04\n",
      "Epoch 626/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 6.0456e-04 - val_loss: 9.5939e-04\n",
      "Epoch 627/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1498e-04 - val_loss: 9.5843e-04\n",
      "Epoch 628/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0983e-04 - val_loss: 9.6497e-04\n",
      "Epoch 629/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1437e-04 - val_loss: 9.7895e-04\n",
      "Epoch 630/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0347e-04 - val_loss: 9.6790e-04\n",
      "Epoch 631/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1210e-04 - val_loss: 9.6978e-04\n",
      "Epoch 632/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0670e-04 - val_loss: 9.6858e-04\n",
      "Epoch 633/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1779e-04 - val_loss: 9.6337e-04\n",
      "Epoch 634/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1764e-04 - val_loss: 9.5753e-04\n",
      "Epoch 635/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0987e-04 - val_loss: 9.5823e-04\n",
      "Epoch 636/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1371e-04 - val_loss: 9.5941e-04\n",
      "Epoch 637/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1746e-04 - val_loss: 9.6044e-04\n",
      "Epoch 638/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1196e-04 - val_loss: 9.6727e-04\n",
      "Epoch 639/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1983e-04 - val_loss: 9.6713e-04\n",
      "Epoch 640/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1361e-04 - val_loss: 9.6978e-04\n",
      "Epoch 641/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1281e-04 - val_loss: 9.6798e-04\n",
      "Epoch 642/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1393e-04 - val_loss: 9.6364e-04\n",
      "Epoch 643/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1742e-04 - val_loss: 9.7450e-04\n",
      "Epoch 644/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2224e-04 - val_loss: 9.6700e-04\n",
      "Epoch 645/1000\n",
      "242/242 [==============================] - 38s 155ms/step - loss: 6.2941e-04 - val_loss: 9.5691e-04\n",
      "Epoch 646/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0972e-04 - val_loss: 9.6244e-04\n",
      "Epoch 647/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0311e-04 - val_loss: 9.5998e-04\n",
      "Epoch 648/1000\n",
      "242/242 [==============================] - 41s 171ms/step - loss: 6.1075e-04 - val_loss: 9.6613e-04\n",
      "Epoch 649/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 6.1064e-04 - val_loss: 9.6266e-04\n",
      "Epoch 650/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1029e-04 - val_loss: 9.6622e-04\n",
      "Epoch 651/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.1378e-04 - val_loss: 9.7497e-04\n",
      "Epoch 652/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0680e-04 - val_loss: 9.7277e-04\n",
      "Epoch 653/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1297e-04 - val_loss: 9.6956e-04\n",
      "Epoch 654/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.0574e-04 - val_loss: 9.6814e-04\n",
      "Epoch 655/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.1166e-04 - val_loss: 9.6394e-04\n",
      "Epoch 656/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.0700e-04 - val_loss: 9.5933e-04\n",
      "Epoch 657/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0483e-04 - val_loss: 9.6128e-04\n",
      "Epoch 658/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9897e-04 - val_loss: 9.7659e-04\n",
      "Epoch 659/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0816e-04 - val_loss: 9.7531e-04\n",
      "Epoch 660/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.0474e-04 - val_loss: 9.6757e-04\n",
      "Epoch 661/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0855e-04 - val_loss: 9.6344e-04\n",
      "Epoch 662/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.0469e-04 - val_loss: 9.6592e-04\n",
      "Epoch 663/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1832e-04 - val_loss: 9.5536e-04\n",
      "Epoch 664/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0521e-04 - val_loss: 9.8497e-04\n",
      "Epoch 665/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0709e-04 - val_loss: 9.8541e-04\n",
      "Epoch 666/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1521e-04 - val_loss: 9.6433e-04\n",
      "Epoch 667/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0421e-04 - val_loss: 9.6548e-04\n",
      "Epoch 668/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.3537e-04 - val_loss: 9.5904e-04\n",
      "Epoch 669/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2015e-04 - val_loss: 9.6273e-04\n",
      "Epoch 670/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1859e-04 - val_loss: 9.6421e-04\n",
      "Epoch 671/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1077e-04 - val_loss: 9.7044e-04\n",
      "Epoch 672/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1992e-04 - val_loss: 9.7607e-04\n",
      "Epoch 673/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0323e-04 - val_loss: 9.7443e-04\n",
      "Epoch 674/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0836e-04 - val_loss: 9.7778e-04\n",
      "Epoch 675/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0232e-04 - val_loss: 9.7824e-04\n",
      "Epoch 676/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1233e-04 - val_loss: 9.6210e-04\n",
      "Epoch 677/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0009e-04 - val_loss: 9.6710e-04\n",
      "Epoch 678/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1358e-04 - val_loss: 9.6450e-04\n",
      "Epoch 679/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0243e-04 - val_loss: 9.7767e-04\n",
      "Epoch 680/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0022e-04 - val_loss: 9.8073e-04\n",
      "Epoch 681/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.0468e-04 - val_loss: 9.6700e-04\n",
      "Epoch 682/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9839e-04 - val_loss: 9.7607e-04\n",
      "Epoch 683/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9503e-04 - val_loss: 9.8396e-04\n",
      "Epoch 684/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9815e-04 - val_loss: 9.7907e-04\n",
      "Epoch 685/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.1172e-04 - val_loss: 9.7037e-04\n",
      "Epoch 686/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0328e-04 - val_loss: 9.6640e-04\n",
      "Epoch 687/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0241e-04 - val_loss: 9.7066e-04\n",
      "Epoch 688/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0120e-04 - val_loss: 9.6388e-04\n",
      "Epoch 689/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0489e-04 - val_loss: 9.8292e-04\n",
      "Epoch 690/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.1002e-04 - val_loss: 9.7346e-04\n",
      "Epoch 691/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1486e-04 - val_loss: 9.7292e-04\n",
      "Epoch 692/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1786e-04 - val_loss: 9.7889e-04\n",
      "Epoch 693/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9556e-04 - val_loss: 9.6931e-04\n",
      "Epoch 694/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0231e-04 - val_loss: 9.7806e-04\n",
      "Epoch 695/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.0313e-04 - val_loss: 9.7540e-04\n",
      "Epoch 696/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.2124e-04 - val_loss: 9.6289e-04\n",
      "Epoch 697/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9653e-04 - val_loss: 9.7060e-04\n",
      "Epoch 698/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 6.0254e-04 - val_loss: 9.7071e-04\n",
      "Epoch 699/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0526e-04 - val_loss: 9.7369e-04\n",
      "Epoch 700/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9820e-04 - val_loss: 9.8048e-04\n",
      "Epoch 701/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9960e-04 - val_loss: 9.7655e-04\n",
      "Epoch 702/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0281e-04 - val_loss: 9.7285e-04\n",
      "Epoch 703/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0292e-04 - val_loss: 9.7560e-04\n",
      "Epoch 704/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9806e-04 - val_loss: 9.6748e-04\n",
      "Epoch 705/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0512e-04 - val_loss: 9.8915e-04\n",
      "Epoch 706/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1083e-04 - val_loss: 9.7290e-04\n",
      "Epoch 707/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 6.0262e-04 - val_loss: 9.7638e-04\n",
      "Epoch 708/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.9446e-04 - val_loss: 9.7578e-04\n",
      "Epoch 709/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9338e-04 - val_loss: 9.8083e-04\n",
      "Epoch 710/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0688e-04 - val_loss: 9.7743e-04\n",
      "Epoch 711/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9839e-04 - val_loss: 9.7096e-04\n",
      "Epoch 712/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9551e-04 - val_loss: 9.6964e-04\n",
      "Epoch 713/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 6.2460e-04 - val_loss: 9.7649e-04\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 155ms/step - loss: 6.0195e-04 - val_loss: 9.9244e-04\n",
      "Epoch 715/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0281e-04 - val_loss: 9.8477e-04\n",
      "Epoch 716/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0228e-04 - val_loss: 9.9815e-04\n",
      "Epoch 717/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0356e-04 - val_loss: 9.7684e-04\n",
      "Epoch 718/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0242e-04 - val_loss: 9.7367e-04\n",
      "Epoch 719/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1285e-04 - val_loss: 9.8623e-04\n",
      "Epoch 720/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0183e-04 - val_loss: 9.7105e-04\n",
      "Epoch 721/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9702e-04 - val_loss: 9.7478e-04\n",
      "Epoch 722/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9366e-04 - val_loss: 9.8193e-04\n",
      "Epoch 723/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9164e-04 - val_loss: 9.8656e-04\n",
      "Epoch 724/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9447e-04 - val_loss: 9.9317e-04\n",
      "Epoch 725/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1562e-04 - val_loss: 9.7859e-04\n",
      "Epoch 726/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0065e-04 - val_loss: 9.6891e-04\n",
      "Epoch 727/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0178e-04 - val_loss: 9.8073e-04\n",
      "Epoch 728/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9693e-04 - val_loss: 9.8584e-04\n",
      "Epoch 729/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9529e-04 - val_loss: 9.9581e-04\n",
      "Epoch 730/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9688e-04 - val_loss: 9.7970e-04\n",
      "Epoch 731/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9565e-04 - val_loss: 9.8078e-04\n",
      "Epoch 732/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9808e-04 - val_loss: 9.8883e-04\n",
      "Epoch 733/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9637e-04 - val_loss: 9.6842e-04\n",
      "Epoch 734/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.1217e-04 - val_loss: 9.7453e-04\n",
      "Epoch 735/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9154e-04 - val_loss: 9.8205e-04\n",
      "Epoch 736/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8936e-04 - val_loss: 9.9336e-04\n",
      "Epoch 737/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9862e-04 - val_loss: 9.9881e-04\n",
      "Epoch 738/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.2303e-04 - val_loss: 9.8809e-04\n",
      "Epoch 739/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 6.0564e-04 - val_loss: 9.7051e-04\n",
      "Epoch 740/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9977e-04 - val_loss: 9.7791e-04\n",
      "Epoch 741/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9880e-04 - val_loss: 9.7910e-04\n",
      "Epoch 742/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9654e-04 - val_loss: 9.7276e-04\n",
      "Epoch 743/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9300e-04 - val_loss: 9.8860e-04\n",
      "Epoch 744/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0198e-04 - val_loss: 9.7626e-04\n",
      "Epoch 745/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0044e-04 - val_loss: 9.7722e-04\n",
      "Epoch 746/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0368e-04 - val_loss: 9.7343e-04\n",
      "Epoch 747/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9742e-04 - val_loss: 9.9237e-04\n",
      "Epoch 748/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9603e-04 - val_loss: 9.7687e-04\n",
      "Epoch 749/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0141e-04 - val_loss: 9.8892e-04\n",
      "Epoch 750/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8731e-04 - val_loss: 9.8289e-04\n",
      "Epoch 751/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9313e-04 - val_loss: 9.9226e-04\n",
      "Epoch 752/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.9132e-04 - val_loss: 9.8061e-04\n",
      "Epoch 753/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9914e-04 - val_loss: 9.9653e-04\n",
      "Epoch 754/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8967e-04 - val_loss: 9.7125e-04\n",
      "Epoch 755/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.8887e-04 - val_loss: 9.7717e-04\n",
      "Epoch 756/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9597e-04 - val_loss: 9.7944e-04\n",
      "Epoch 757/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9036e-04 - val_loss: 9.9218e-04\n",
      "Epoch 758/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0040e-04 - val_loss: 9.7716e-04\n",
      "Epoch 759/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0619e-04 - val_loss: 9.9538e-04\n",
      "Epoch 760/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0759e-04 - val_loss: 9.8205e-04\n",
      "Epoch 761/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 5.9850e-04 - val_loss: 9.7563e-04\n",
      "Epoch 762/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9883e-04 - val_loss: 9.7865e-04\n",
      "Epoch 763/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0207e-04 - val_loss: 9.8079e-04\n",
      "Epoch 764/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.1004e-04 - val_loss: 9.8744e-04\n",
      "Epoch 765/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8497e-04 - val_loss: 9.7489e-04\n",
      "Epoch 766/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9463e-04 - val_loss: 9.8671e-04\n",
      "Epoch 767/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0059e-04 - val_loss: 9.9621e-04\n",
      "Epoch 768/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9174e-04 - val_loss: 9.9184e-04\n",
      "Epoch 769/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8595e-04 - val_loss: 9.9078e-04\n",
      "Epoch 770/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9540e-04 - val_loss: 9.8942e-04\n",
      "Epoch 771/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9718e-04 - val_loss: 9.8129e-04\n",
      "Epoch 772/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.9525e-04 - val_loss: 9.7606e-04\n",
      "Epoch 773/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9167e-04 - val_loss: 9.8201e-04\n",
      "Epoch 774/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0304e-04 - val_loss: 9.9022e-04\n",
      "Epoch 775/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8716e-04 - val_loss: 9.9051e-04\n",
      "Epoch 776/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9195e-04 - val_loss: 9.8419e-04\n",
      "Epoch 777/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.8685e-04 - val_loss: 9.9871e-04\n",
      "Epoch 778/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9136e-04 - val_loss: 9.9056e-04\n",
      "Epoch 779/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9536e-04 - val_loss: 9.9344e-04\n",
      "Epoch 780/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 6.0787e-04 - val_loss: 9.9862e-04\n",
      "Epoch 781/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9379e-04 - val_loss: 9.8575e-04\n",
      "Epoch 782/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0144e-04 - val_loss: 9.9347e-04\n",
      "Epoch 783/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9571e-04 - val_loss: 9.8114e-04\n",
      "Epoch 784/1000\n",
      "242/242 [==============================] - 38s 157ms/step - loss: 5.8956e-04 - val_loss: 9.7717e-04\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9148e-04 - val_loss: 9.8628e-04\n",
      "Epoch 786/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 6.0196e-04 - val_loss: 9.9875e-04\n",
      "Epoch 787/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9257e-04 - val_loss: 9.8982e-04\n",
      "Epoch 788/1000\n",
      "242/242 [==============================] - 38s 158ms/step - loss: 6.0010e-04 - val_loss: 9.8526e-04\n",
      "Epoch 789/1000\n",
      "242/242 [==============================] - 38s 156ms/step - loss: 5.9302e-04 - val_loss: 9.9706e-04\n",
      "Epoch 790/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0032e-04 - val_loss: 9.8702e-04\n",
      "Epoch 791/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.9413e-04 - val_loss: 9.8143e-04\n",
      "Epoch 792/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9993e-04 - val_loss: 9.8131e-04\n",
      "Epoch 793/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8976e-04 - val_loss: 9.9893e-04\n",
      "Epoch 794/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.8889e-04 - val_loss: 9.8070e-04\n",
      "Epoch 795/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8485e-04 - val_loss: 9.8777e-04\n",
      "Epoch 796/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 6.0094e-04 - val_loss: 9.9133e-04\n",
      "Epoch 797/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.9531e-04 - val_loss: 9.7286e-04\n",
      "Epoch 798/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.9486e-04 - val_loss: 9.8264e-04\n",
      "Epoch 799/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.9100e-04 - val_loss: 9.7906e-04\n",
      "Epoch 800/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8745e-04 - val_loss: 9.9379e-04\n",
      "Epoch 801/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.8641e-04 - val_loss: 9.8230e-04\n",
      "Epoch 802/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8408e-04 - val_loss: 9.8934e-04\n",
      "Epoch 803/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8763e-04 - val_loss: 9.7752e-04\n",
      "Epoch 804/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8822e-04 - val_loss: 9.8324e-04\n",
      "Epoch 805/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8559e-04 - val_loss: 9.8160e-04\n",
      "Epoch 806/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9146e-04 - val_loss: 9.9370e-04\n",
      "Epoch 807/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0131e-04 - val_loss: 9.8500e-04\n",
      "Epoch 808/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9770e-04 - val_loss: 9.8620e-04\n",
      "Epoch 809/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8612e-04 - val_loss: 9.9308e-04\n",
      "Epoch 810/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9162e-04 - val_loss: 9.8777e-04\n",
      "Epoch 811/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9097e-04 - val_loss: 9.8849e-04\n",
      "Epoch 812/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8825e-04 - val_loss: 9.9147e-04\n",
      "Epoch 813/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9323e-04 - val_loss: 9.9387e-04\n",
      "Epoch 814/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9516e-04 - val_loss: 9.8376e-04\n",
      "Epoch 815/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.9198e-04 - val_loss: 9.8554e-04\n",
      "Epoch 816/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8263e-04 - val_loss: 9.8101e-04\n",
      "Epoch 817/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8489e-04 - val_loss: 9.8669e-04\n",
      "Epoch 818/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.9257e-04 - val_loss: 9.9061e-04\n",
      "Epoch 819/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8181e-04 - val_loss: 0.0010\n",
      "Epoch 820/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8194e-04 - val_loss: 9.9162e-04\n",
      "Epoch 821/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 6.0194e-04 - val_loss: 9.8857e-04\n",
      "Epoch 822/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8405e-04 - val_loss: 9.8068e-04\n",
      "Epoch 823/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8863e-04 - val_loss: 9.9189e-04\n",
      "Epoch 824/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8656e-04 - val_loss: 9.8175e-04\n",
      "Epoch 825/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.9251e-04 - val_loss: 9.9282e-04\n",
      "Epoch 826/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8323e-04 - val_loss: 9.9530e-04\n",
      "Epoch 827/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8299e-04 - val_loss: 9.9511e-04\n",
      "Epoch 828/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.8498e-04 - val_loss: 9.8558e-04\n",
      "Epoch 829/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8681e-04 - val_loss: 9.9177e-04\n",
      "Epoch 830/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8641e-04 - val_loss: 9.8347e-04\n",
      "Epoch 831/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8613e-04 - val_loss: 9.7938e-04\n",
      "Epoch 832/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.9001e-04 - val_loss: 9.8349e-04\n",
      "Epoch 833/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8054e-04 - val_loss: 0.0010\n",
      "Epoch 834/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8297e-04 - val_loss: 9.9052e-04\n",
      "Epoch 835/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7755e-04 - val_loss: 9.8708e-04\n",
      "Epoch 836/1000\n",
      "242/242 [==============================] - 40s 164ms/step - loss: 5.8389e-04 - val_loss: 9.8820e-04\n",
      "Epoch 837/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8637e-04 - val_loss: 9.9554e-04\n",
      "Epoch 838/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8702e-04 - val_loss: 9.9048e-04\n",
      "Epoch 839/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8563e-04 - val_loss: 9.7919e-04\n",
      "Epoch 840/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8549e-04 - val_loss: 9.9420e-04\n",
      "Epoch 841/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7936e-04 - val_loss: 9.8664e-04\n",
      "Epoch 842/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7747e-04 - val_loss: 0.0010\n",
      "Epoch 843/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.8619e-04 - val_loss: 9.9295e-04\n",
      "Epoch 844/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8092e-04 - val_loss: 9.9031e-04\n",
      "Epoch 845/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8297e-04 - val_loss: 9.8849e-04\n",
      "Epoch 846/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7708e-04 - val_loss: 9.8749e-04\n",
      "Epoch 847/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8333e-04 - val_loss: 9.8386e-04\n",
      "Epoch 848/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9498e-04 - val_loss: 9.8822e-04\n",
      "Epoch 849/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.9037e-04 - val_loss: 9.9151e-04\n",
      "Epoch 850/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8039e-04 - val_loss: 9.9543e-04\n",
      "Epoch 851/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.9321e-04 - val_loss: 9.8532e-04\n",
      "Epoch 852/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.9129e-04 - val_loss: 9.9876e-04\n",
      "Epoch 853/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7553e-04 - val_loss: 9.9004e-04\n",
      "Epoch 854/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7795e-04 - val_loss: 9.9445e-04\n",
      "Epoch 855/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8497e-04 - val_loss: 9.9317e-04\n",
      "Epoch 856/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8225e-04 - val_loss: 9.9558e-04\n",
      "Epoch 857/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8140e-04 - val_loss: 9.8617e-04\n",
      "Epoch 858/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8553e-04 - val_loss: 9.9165e-04\n",
      "Epoch 859/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.8087e-04 - val_loss: 9.9471e-04\n",
      "Epoch 860/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7362e-04 - val_loss: 9.9083e-04\n",
      "Epoch 861/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8437e-04 - val_loss: 9.9250e-04\n",
      "Epoch 862/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8533e-04 - val_loss: 9.9261e-04\n",
      "Epoch 863/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7993e-04 - val_loss: 9.8695e-04\n",
      "Epoch 864/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8063e-04 - val_loss: 0.0010\n",
      "Epoch 865/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8232e-04 - val_loss: 0.0010\n",
      "Epoch 866/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7597e-04 - val_loss: 9.9569e-04\n",
      "Epoch 867/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8621e-04 - val_loss: 9.9743e-04\n",
      "Epoch 868/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7774e-04 - val_loss: 9.9443e-04\n",
      "Epoch 869/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8211e-04 - val_loss: 9.9665e-04\n",
      "Epoch 870/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8443e-04 - val_loss: 9.8763e-04\n",
      "Epoch 871/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8212e-04 - val_loss: 9.9742e-04\n",
      "Epoch 872/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8257e-04 - val_loss: 9.9900e-04\n",
      "Epoch 873/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7743e-04 - val_loss: 9.9204e-04\n",
      "Epoch 874/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7845e-04 - val_loss: 0.0010\n",
      "Epoch 875/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7694e-04 - val_loss: 0.0010\n",
      "Epoch 876/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8248e-04 - val_loss: 9.8883e-04\n",
      "Epoch 877/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7729e-04 - val_loss: 9.9312e-04\n",
      "Epoch 878/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8047e-04 - val_loss: 0.0010\n",
      "Epoch 879/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7974e-04 - val_loss: 9.9570e-04\n",
      "Epoch 880/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8041e-04 - val_loss: 9.9511e-04\n",
      "Epoch 881/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8458e-04 - val_loss: 0.0010\n",
      "Epoch 882/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8120e-04 - val_loss: 9.9635e-04\n",
      "Epoch 883/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7219e-04 - val_loss: 9.9526e-04\n",
      "Epoch 884/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7982e-04 - val_loss: 9.9670e-04\n",
      "Epoch 885/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7736e-04 - val_loss: 9.8448e-04\n",
      "Epoch 886/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7890e-04 - val_loss: 9.9225e-04\n",
      "Epoch 887/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8319e-04 - val_loss: 0.0010\n",
      "Epoch 888/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9467e-04 - val_loss: 0.0010\n",
      "Epoch 889/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8748e-04 - val_loss: 0.0010\n",
      "Epoch 890/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7656e-04 - val_loss: 9.9204e-04\n",
      "Epoch 891/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7525e-04 - val_loss: 9.9055e-04\n",
      "Epoch 892/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7666e-04 - val_loss: 9.8511e-04\n",
      "Epoch 893/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8305e-04 - val_loss: 9.9741e-04\n",
      "Epoch 894/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9384e-04 - val_loss: 9.9468e-04\n",
      "Epoch 895/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8458e-04 - val_loss: 0.0010\n",
      "Epoch 896/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8287e-04 - val_loss: 0.0010\n",
      "Epoch 897/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7022e-04 - val_loss: 0.0010\n",
      "Epoch 898/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8491e-04 - val_loss: 0.0010\n",
      "Epoch 899/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7403e-04 - val_loss: 9.9249e-04\n",
      "Epoch 900/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7704e-04 - val_loss: 9.9301e-04\n",
      "Epoch 901/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7878e-04 - val_loss: 9.9782e-04\n",
      "Epoch 902/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7335e-04 - val_loss: 9.9931e-04\n",
      "Epoch 903/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8161e-04 - val_loss: 0.0010\n",
      "Epoch 904/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7270e-04 - val_loss: 0.0010\n",
      "Epoch 905/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8374e-04 - val_loss: 9.8133e-04\n",
      "Epoch 906/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7526e-04 - val_loss: 0.0010\n",
      "Epoch 907/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.8115e-04 - val_loss: 9.9278e-04\n",
      "Epoch 908/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.8039e-04 - val_loss: 9.9955e-04\n",
      "Epoch 909/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7762e-04 - val_loss: 0.0010\n",
      "Epoch 910/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7372e-04 - val_loss: 0.0010\n",
      "Epoch 911/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7343e-04 - val_loss: 0.0010\n",
      "Epoch 912/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7609e-04 - val_loss: 0.0010\n",
      "Epoch 913/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7405e-04 - val_loss: 9.9845e-04\n",
      "Epoch 914/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7954e-04 - val_loss: 9.8900e-04\n",
      "Epoch 915/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.8511e-04 - val_loss: 0.0010\n",
      "Epoch 916/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8053e-04 - val_loss: 0.0010\n",
      "Epoch 917/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7505e-04 - val_loss: 0.0010\n",
      "Epoch 918/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7201e-04 - val_loss: 0.0010\n",
      "Epoch 919/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9177e-04 - val_loss: 9.9470e-04\n",
      "Epoch 920/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7617e-04 - val_loss: 9.9541e-04\n",
      "Epoch 921/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7410e-04 - val_loss: 0.0010\n",
      "Epoch 922/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7150e-04 - val_loss: 0.0010\n",
      "Epoch 923/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7231e-04 - val_loss: 0.0010\n",
      "Epoch 924/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7510e-04 - val_loss: 0.0010\n",
      "Epoch 925/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7323e-04 - val_loss: 0.0010\n",
      "Epoch 926/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.6859e-04 - val_loss: 9.9250e-04\n",
      "Epoch 927/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7591e-04 - val_loss: 9.9438e-04\n",
      "Epoch 928/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7400e-04 - val_loss: 0.0010\n",
      "Epoch 929/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7053e-04 - val_loss: 9.9581e-04\n",
      "Epoch 930/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7428e-04 - val_loss: 9.9935e-04\n",
      "Epoch 931/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7659e-04 - val_loss: 0.0010\n",
      "Epoch 932/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7122e-04 - val_loss: 9.9030e-04\n",
      "Epoch 933/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7501e-04 - val_loss: 0.0010\n",
      "Epoch 934/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7618e-04 - val_loss: 0.0010\n",
      "Epoch 935/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 6.3383e-04 - val_loss: 9.9425e-04\n",
      "Epoch 936/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8732e-04 - val_loss: 0.0010\n",
      "Epoch 937/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.6973e-04 - val_loss: 9.9183e-04\n",
      "Epoch 938/1000\n",
      "242/242 [==============================] - 39s 163ms/step - loss: 5.7907e-04 - val_loss: 9.9495e-04\n",
      "Epoch 939/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7237e-04 - val_loss: 9.9613e-04\n",
      "Epoch 940/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6775e-04 - val_loss: 0.0010\n",
      "Epoch 941/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.6980e-04 - val_loss: 0.0010\n",
      "Epoch 942/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7241e-04 - val_loss: 0.0010\n",
      "Epoch 943/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8263e-04 - val_loss: 0.0010\n",
      "Epoch 944/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7488e-04 - val_loss: 9.9341e-04\n",
      "Epoch 945/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7217e-04 - val_loss: 9.9591e-04\n",
      "Epoch 946/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.9100e-04 - val_loss: 0.0010\n",
      "Epoch 947/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7663e-04 - val_loss: 0.0010\n",
      "Epoch 948/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7710e-04 - val_loss: 0.0010\n",
      "Epoch 949/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7142e-04 - val_loss: 0.0010\n",
      "Epoch 950/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7261e-04 - val_loss: 9.9686e-04\n",
      "Epoch 951/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.9357e-04 - val_loss: 0.0010\n",
      "Epoch 952/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7652e-04 - val_loss: 9.9923e-04\n",
      "Epoch 953/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7463e-04 - val_loss: 9.9873e-04\n",
      "Epoch 954/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7582e-04 - val_loss: 0.0010\n",
      "Epoch 955/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6736e-04 - val_loss: 0.0010\n",
      "Epoch 956/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.7243e-04 - val_loss: 0.0010\n",
      "Epoch 957/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8991e-04 - val_loss: 0.0010\n",
      "Epoch 958/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7009e-04 - val_loss: 9.9630e-04\n",
      "Epoch 959/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.7078e-04 - val_loss: 0.0010\n",
      "Epoch 960/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7069e-04 - val_loss: 9.9408e-04\n",
      "Epoch 961/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7074e-04 - val_loss: 0.0010\n",
      "Epoch 962/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.6825e-04 - val_loss: 0.0010\n",
      "Epoch 963/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6958e-04 - val_loss: 0.0010\n",
      "Epoch 964/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7327e-04 - val_loss: 0.0010\n",
      "Epoch 965/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7258e-04 - val_loss: 0.0010\n",
      "Epoch 966/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8112e-04 - val_loss: 0.0010\n",
      "Epoch 967/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.6635e-04 - val_loss: 9.9593e-04\n",
      "Epoch 968/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.7149e-04 - val_loss: 0.0010\n",
      "Epoch 969/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.8260e-04 - val_loss: 0.0010\n",
      "Epoch 970/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.6753e-04 - val_loss: 0.0010\n",
      "Epoch 971/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6987e-04 - val_loss: 0.0010\n",
      "Epoch 972/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7358e-04 - val_loss: 0.0010\n",
      "Epoch 973/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6753e-04 - val_loss: 0.0010\n",
      "Epoch 974/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7020e-04 - val_loss: 0.0010\n",
      "Epoch 975/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7633e-04 - val_loss: 0.0010\n",
      "Epoch 976/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6663e-04 - val_loss: 9.9656e-04\n",
      "Epoch 977/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.8460e-04 - val_loss: 0.0010\n",
      "Epoch 978/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.6436e-04 - val_loss: 0.0010\n",
      "Epoch 979/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6699e-04 - val_loss: 0.0010\n",
      "Epoch 980/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6825e-04 - val_loss: 0.0010\n",
      "Epoch 981/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7030e-04 - val_loss: 9.9578e-04\n",
      "Epoch 982/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7589e-04 - val_loss: 0.0010\n",
      "Epoch 983/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6677e-04 - val_loss: 0.0010\n",
      "Epoch 984/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6828e-04 - val_loss: 0.0010\n",
      "Epoch 985/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7127e-04 - val_loss: 0.0010\n",
      "Epoch 986/1000\n",
      "242/242 [==============================] - 39s 162ms/step - loss: 5.7581e-04 - val_loss: 0.0010\n",
      "Epoch 987/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.8583e-04 - val_loss: 0.0010\n",
      "Epoch 988/1000\n",
      "242/242 [==============================] - 39s 160ms/step - loss: 5.7701e-04 - val_loss: 0.0010\n",
      "Epoch 989/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7908e-04 - val_loss: 0.0010\n",
      "Epoch 990/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6603e-04 - val_loss: 0.0010\n",
      "Epoch 991/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.7651e-04 - val_loss: 0.0010\n",
      "Epoch 992/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.7151e-04 - val_loss: 0.0010\n",
      "Epoch 993/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.6464e-04 - val_loss: 0.0010\n",
      "Epoch 994/1000\n",
      "242/242 [==============================] - 39s 161ms/step - loss: 5.7491e-04 - val_loss: 0.0010\n",
      "Epoch 995/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.8602e-04 - val_loss: 0.0010\n",
      "Epoch 996/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6552e-04 - val_loss: 0.0010\n",
      "Epoch 997/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6471e-04 - val_loss: 0.0010\n",
      "Epoch 998/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.5933e-04 - val_loss: 0.0010\n",
      "Epoch 999/1000\n",
      "242/242 [==============================] - 38s 159ms/step - loss: 5.6262e-04 - val_loss: 0.0010\n",
      "Epoch 1000/1000\n",
      "242/242 [==============================] - 39s 159ms/step - loss: 5.7079e-04 - val_loss: 0.0010\n",
      "Train_Temps = 38237.899141\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tmps_train=time.time()\n",
    "history=model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False\n",
    ")\n",
    "tmps_t2=time.time()-tmps_train\n",
    "print (\"Train_Temps = %f\" %tmps_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ea28082948>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 4s 56ms/step - loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save(\"Bilstm_TM_1.h5\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 1000)              4120000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 529)               529529    \n",
      "=================================================================\n",
      "Total params: 4,649,529\n",
      "Trainable params: 4,649,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('Bilstm_TM_1.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_shape (2142, 529)\n",
      "       0         1         2         3         4         5         6    \\\n",
      "0     0.0  0.000801  0.000080  0.007324  0.008302  0.000181  0.000000   \n",
      "1     0.0  0.000507  0.000937  0.008774  0.022361  0.000137  0.000008   \n",
      "2     0.0  0.000994  0.000280  0.007561  0.007226  0.000148  0.000000   \n",
      "3     0.0  0.000499  0.000055  0.008047  0.012882  0.000157  0.000004   \n",
      "4     0.0  0.000427  0.000012  0.010481  0.002219  0.000157  0.000000   \n",
      "...   ...       ...       ...       ...       ...       ...       ...   \n",
      "2137  0.0  0.026102  0.000000  0.043389  0.016551  0.000065  0.000405   \n",
      "2138  0.0  0.012493  0.000000  0.107327  0.120661  0.000103  0.000009   \n",
      "2139  0.0  0.004733  0.000000  0.121103  0.384409  0.000096  0.000005   \n",
      "2140  0.0  0.006294  0.000000  0.090306  0.052256  0.000095  0.000002   \n",
      "2141  0.0  0.013714  0.000000  0.029197  0.029333  0.000114  0.000003   \n",
      "\n",
      "           7             8         9    ...  519       520       521  \\\n",
      "0     0.000031  1.470093e-06  0.000297  ...  0.0  0.002376  0.012196   \n",
      "1     0.000085  2.151355e-06  0.000221  ...  0.0  0.003527  0.019184   \n",
      "2     0.000099  2.648681e-06  0.000093  ...  0.0  0.004448  0.015838   \n",
      "3     0.000107  9.126960e-08  0.000165  ...  0.0  0.002909  0.007785   \n",
      "4     0.000137  8.009375e-08  0.000069  ...  0.0  0.003815  0.006448   \n",
      "...        ...           ...       ...  ...  ...       ...       ...   \n",
      "2137  0.000261  6.122515e-06  0.000064  ...  0.0  0.066571  0.002322   \n",
      "2138  0.000266  8.248724e-06  0.000050  ...  0.0  0.068285  0.002711   \n",
      "2139  0.000305  7.848255e-06  0.000059  ...  0.0  0.063666  0.004873   \n",
      "2140  0.000139  6.989110e-06  0.000054  ...  0.0  0.068218  0.001620   \n",
      "2141  0.000133  1.574215e-05  0.000065  ...  0.0  0.063000  0.005092   \n",
      "\n",
      "           522       523       524       525       526       527  528  \n",
      "0     0.033446  0.013130  0.041627  0.007290  0.000010  0.000082  0.0  \n",
      "1     0.024823  0.015372  0.059282  0.007464  0.000011  0.000000  0.0  \n",
      "2     0.029828  0.014502  0.052082  0.007442  0.000012  0.009889  0.0  \n",
      "3     0.021880  0.017085  0.045540  0.007524  0.000014  0.013240  0.0  \n",
      "4     0.027911  0.016807  0.047226  0.007395  0.000004  0.014219  0.0  \n",
      "...        ...       ...       ...       ...       ...       ...  ...  \n",
      "2137  0.023177  0.001981  0.045390  0.005981  0.000013  0.003035  0.0  \n",
      "2138  0.009657  0.002193  0.049673  0.006105  0.000023  0.002048  0.0  \n",
      "2139  0.013145  0.001417  0.043085  0.006159  0.000021  0.000000  0.0  \n",
      "2140  0.012213  0.001731  0.048092  0.005964  0.000018  0.000215  0.0  \n",
      "2141  0.017792  0.002570  0.048482  0.005855  0.000003  0.000000  0.0  \n",
      "\n",
      "[2142 rows x 529 columns]\n",
      "\n",
      "y_pred_shape (2142, 529)\n",
      "           0         1         2         3         4         5         6    \\\n",
      "0     0.000841  0.037927  0.019978  0.051141  0.037726 -0.000266  0.050440   \n",
      "1     0.001771  0.023464  0.017958  0.061319  0.040848 -0.000323  0.061025   \n",
      "2     0.001493  0.029955  0.023169  0.045922  0.042237 -0.000398  0.085371   \n",
      "3     0.000941  0.033920  0.019473  0.036176  0.042495 -0.000338  0.045843   \n",
      "4     0.000689  0.029402  0.021884  0.033296  0.034247 -0.000412  0.029909   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2137 -0.000016  0.003144  0.027885  0.077408  0.019044 -0.000895 -0.008712   \n",
      "2138 -0.001212  0.001810  0.026813  0.059727  0.024797 -0.000589 -0.007597   \n",
      "2139 -0.000323 -0.001431  0.020779  0.058900  0.039167 -0.000491  0.008288   \n",
      "2140  0.000174 -0.010057  0.018571  0.064009  0.163998 -0.000268  0.006904   \n",
      "2141  0.000524 -0.007406  0.025012  0.051655  0.090933  0.000086  0.000272   \n",
      "\n",
      "           7         8         9    ...       519       520       521  \\\n",
      "0    -0.000371 -0.000524  0.000512  ...  0.012814  0.004701  0.025678   \n",
      "1    -0.000364 -0.000873  0.000007  ...  0.031251  0.005350  0.021030   \n",
      "2    -0.000521 -0.000837  0.000019  ...  0.026523  0.006700  0.023865   \n",
      "3    -0.000549 -0.000600  0.000474  ...  0.017759  0.009228  0.022576   \n",
      "4    -0.000573 -0.000553  0.000455  ...  0.010425  0.007927  0.017591   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2137 -0.000821 -0.001464 -0.001316  ...  0.009830  0.022302  0.014554   \n",
      "2138 -0.000441 -0.001294 -0.001058  ...  0.013757  0.022056  0.012806   \n",
      "2139 -0.000319 -0.001024 -0.001061  ...  0.021563  0.022716  0.014777   \n",
      "2140 -0.000024 -0.000816 -0.001169  ...  0.028960  0.025486  0.017651   \n",
      "2141  0.000342 -0.000473 -0.000481  ...  0.031936  0.026409  0.015171   \n",
      "\n",
      "           522       523       524       525       526       527       528  \n",
      "0     0.022973  0.022693  0.053648  0.006129 -0.000394  0.000001 -0.000653  \n",
      "1     0.022936  0.019638  0.071476  0.005751 -0.000404  0.001898 -0.000479  \n",
      "2     0.025490  0.020807  0.077644  0.005714 -0.000573  0.001965 -0.000288  \n",
      "3     0.031978  0.021779  0.067525  0.005789 -0.000609  0.002064 -0.000606  \n",
      "4     0.035055  0.020426  0.057395  0.005501 -0.000637  0.000993  0.000216  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2137  0.018559  0.006212  0.049170  0.004022 -0.000856  0.000860 -0.000648  \n",
      "2138  0.025535  0.006268  0.058525  0.004393 -0.000482  0.002273 -0.000843  \n",
      "2139  0.032751  0.004996  0.063028  0.004380 -0.000349  0.001302 -0.000296  \n",
      "2140  0.040408  0.005873  0.069757  0.004680 -0.000037  0.001386 -0.000181  \n",
      "2141  0.037760  0.005876  0.077329  0.004956  0.000310  0.001445 -0.000287  \n",
      "\n",
      "[2142 rows x 529 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "print(\"y_test_shape\", y_test.shape)\n",
    "print(\"\", y_test)\n",
    "print(\"\")\n",
    "print(\"y_pred_shape\", y_pred.shape)\n",
    "#print(\"y_pred\", y_pred)\n",
    "y_pred=pd.DataFrame(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test (2142, 529)\n",
      "y_train (2142, 529)\n",
      "actual (2142, 529)\n",
      "predictions (2142, 529)\n",
      "Bilstm_TM_1:\n",
      "Mean Square Error: 0.001495595725161294\n",
      "Root Mean Square Error: 0.014579350918614347\n",
      "Mean Absolute Error: 0.014536570299859055\n"
     ]
    }
   ],
   "source": [
    "def evaluate_prediction(predictions, actual, model_name):\n",
    "    errors = predictions - actual\n",
    "    print(\"actual\", actual.shape)\n",
    "    print(\"predictions\", predictions.shape)\n",
    "    mse = np.square(errors)\n",
    "    mse['mean'] = mse.mean(axis=1)\n",
    "    #print(mse)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse['mean'] = rmse.mean(axis=1)\n",
    "    #print(rmse)\n",
    "    mae = np.abs(errors)\n",
    "    mae['mean'] = mae.mean(axis=1)\n",
    "    #mape['mean'] = mape.mean(axis=1)\n",
    "    #print(mae)\n",
    "    print(model_name + \":\")\n",
    "    print(\"Mean Square Error:\", mse['mean'].mean(axis=0))\n",
    "    print(\"Root Mean Square Error:\", rmse['mean'].mean(axis=0))\n",
    "    print(\"Mean Absolute Error:\", mae['mean'].mean(axis=0))\n",
    "    \n",
    "\n",
    "print(\"y_test\", y_test.shape)\n",
    "print(\"y_train\", y_pred.shape)\n",
    "evaluate_prediction(y_pred, y_test, \"Bilstm_TM_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
